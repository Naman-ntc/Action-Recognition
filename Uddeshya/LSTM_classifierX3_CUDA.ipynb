{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9e5c0294d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import random, numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the datasets, i.e loading frames for few actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.382997</td>\n",
       "      <td>-0.419442</td>\n",
       "      <td>3.449989</td>\n",
       "      <td>-0.366909</td>\n",
       "      <td>-0.092619</td>\n",
       "      <td>3.443680</td>\n",
       "      <td>-0.353380</td>\n",
       "      <td>0.229542</td>\n",
       "      <td>3.427116</td>\n",
       "      <td>-0.391862</td>\n",
       "      <td>...</td>\n",
       "      <td>3.636719</td>\n",
       "      <td>-0.435790</td>\n",
       "      <td>-0.536338</td>\n",
       "      <td>3.280097</td>\n",
       "      <td>-0.364369</td>\n",
       "      <td>-0.491436</td>\n",
       "      <td>3.269750</td>\n",
       "      <td>1</td>\n",
       "      <td>72057594037944340</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.383146</td>\n",
       "      <td>-0.419292</td>\n",
       "      <td>3.450006</td>\n",
       "      <td>-0.367569</td>\n",
       "      <td>-0.092003</td>\n",
       "      <td>3.443895</td>\n",
       "      <td>-0.353885</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>3.427162</td>\n",
       "      <td>-0.391820</td>\n",
       "      <td>...</td>\n",
       "      <td>3.633053</td>\n",
       "      <td>-0.436031</td>\n",
       "      <td>-0.536649</td>\n",
       "      <td>3.281972</td>\n",
       "      <td>-0.358806</td>\n",
       "      <td>-0.471054</td>\n",
       "      <td>3.269975</td>\n",
       "      <td>1</td>\n",
       "      <td>72057594037944340</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.385776</td>\n",
       "      <td>-0.421191</td>\n",
       "      <td>3.449611</td>\n",
       "      <td>-0.369506</td>\n",
       "      <td>-0.092775</td>\n",
       "      <td>3.443796</td>\n",
       "      <td>-0.354571</td>\n",
       "      <td>0.230189</td>\n",
       "      <td>3.426965</td>\n",
       "      <td>-0.403822</td>\n",
       "      <td>...</td>\n",
       "      <td>3.632370</td>\n",
       "      <td>-0.436489</td>\n",
       "      <td>-0.536484</td>\n",
       "      <td>3.286322</td>\n",
       "      <td>-0.358079</td>\n",
       "      <td>-0.470344</td>\n",
       "      <td>3.270202</td>\n",
       "      <td>1</td>\n",
       "      <td>72057594037944340</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.385807</td>\n",
       "      <td>-0.421205</td>\n",
       "      <td>3.449582</td>\n",
       "      <td>-0.369576</td>\n",
       "      <td>-0.092714</td>\n",
       "      <td>3.443878</td>\n",
       "      <td>-0.354524</td>\n",
       "      <td>0.230369</td>\n",
       "      <td>3.427140</td>\n",
       "      <td>-0.403580</td>\n",
       "      <td>...</td>\n",
       "      <td>3.499778</td>\n",
       "      <td>-0.441701</td>\n",
       "      <td>-0.533234</td>\n",
       "      <td>3.278971</td>\n",
       "      <td>-0.360298</td>\n",
       "      <td>-0.476572</td>\n",
       "      <td>3.268953</td>\n",
       "      <td>1</td>\n",
       "      <td>72057594037944340</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.357840</td>\n",
       "      <td>-0.420304</td>\n",
       "      <td>3.438846</td>\n",
       "      <td>-0.364956</td>\n",
       "      <td>-0.092426</td>\n",
       "      <td>3.442334</td>\n",
       "      <td>-0.354907</td>\n",
       "      <td>0.230391</td>\n",
       "      <td>3.427352</td>\n",
       "      <td>-0.405945</td>\n",
       "      <td>...</td>\n",
       "      <td>3.400878</td>\n",
       "      <td>-0.430001</td>\n",
       "      <td>-0.536492</td>\n",
       "      <td>3.278641</td>\n",
       "      <td>-0.358697</td>\n",
       "      <td>-0.471415</td>\n",
       "      <td>3.270685</td>\n",
       "      <td>1</td>\n",
       "      <td>72057594037944340</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.382997 -0.419442  3.449989 -0.366909 -0.092619  3.443680 -0.353380   \n",
       "1 -0.383146 -0.419292  3.450006 -0.367569 -0.092003  3.443895 -0.353885   \n",
       "2 -0.385776 -0.421191  3.449611 -0.369506 -0.092775  3.443796 -0.354571   \n",
       "3 -0.385807 -0.421205  3.449582 -0.369576 -0.092714  3.443878 -0.354524   \n",
       "4 -0.357840 -0.420304  3.438846 -0.364956 -0.092426  3.442334 -0.354907   \n",
       "\n",
       "          7         8         9    ...           68        69        70  \\\n",
       "0  0.229542  3.427116 -0.391862    ...     3.636719 -0.435790 -0.536338   \n",
       "1  0.230300  3.427162 -0.391820    ...     3.633053 -0.436031 -0.536649   \n",
       "2  0.230189  3.426965 -0.403822    ...     3.632370 -0.436489 -0.536484   \n",
       "3  0.230369  3.427140 -0.403580    ...     3.499778 -0.441701 -0.533234   \n",
       "4  0.230391  3.427352 -0.405945    ...     3.400878 -0.430001 -0.536492   \n",
       "\n",
       "         71        72        73        74  label                 id  video_id  \n",
       "0  3.280097 -0.364369 -0.491436  3.269750      1  72057594037944340         0  \n",
       "1  3.281972 -0.358806 -0.471054  3.269975      1  72057594037944340         0  \n",
       "2  3.286322 -0.358079 -0.470344  3.270202      1  72057594037944340         0  \n",
       "3  3.278971 -0.360298 -0.476572  3.268953      1  72057594037944340         0  \n",
       "4  3.278641 -0.358697 -0.471415  3.270685      1  72057594037944340         0  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading and prepping data\n",
    "#initially only one action\n",
    "dframe = pd.read_csv('./csv_data/action_1.csv')\n",
    "dframe2 = pd.read_csv('./csv_data/action_2.csv')\n",
    "dframe3 = pd.read_csv('./csv_data/action_3.csv')\n",
    "dframe4 = pd.read_csv('./csv_data/action_4.csv')\n",
    "dframe5 = pd.read_csv('./csv_data/action_5.csv')\n",
    "dframe6 = pd.read_csv('./csv_data/action_6.csv')\n",
    "dframe7 = pd.read_csv('./csv_data/action_7.csv')\n",
    "\n",
    "#to look at data\n",
    "dframe.iloc[0:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some utility functions to split the datasets and loading the datasets in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ (array([[ 0.       ,  0.       ,  0.       , ...,  0.0186279, -0.0719937,\n",
       "        -0.180239 ],\n",
       "       [ 0.       ,  0.       ,  0.       , ...,  0.0243399, -0.0517625,\n",
       "        -0.180031 ],\n",
       "       [ 0.       ,  0.       ,  0.       , ...,  0.0276977, -0.0491529,\n",
       "        -0.179409 ],\n",
       "       ..., \n",
       "       [ 0.       ,  0.       ,  0.       , ..., -0.0563203, -0.0113986,\n",
       "        -0.174284 ],\n",
       "       [ 0.       ,  0.       ,  0.       , ..., -0.0561737, -0.0162162,\n",
       "        -0.171437 ],\n",
       "       [ 0.       ,  0.       ,  0.       , ..., -0.0559275, -0.0062211,\n",
       "        -0.172233 ]]), 0),\n",
       "       (array([[ 0.        ,  0.        ,  0.        , ...,  0.01849598,\n",
       "         0.0721854 , -0.16189   ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.10443107,\n",
       "         0.05172237, -0.133567  ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.08676113,\n",
       "         0.05116256, -0.145192  ],\n",
       "       ..., \n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.10355284,\n",
       "         0.52594266, -0.431462  ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.09376174,\n",
       "         0.53507   , -0.434229  ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.08766792,\n",
       "         0.541823  , -0.422078  ]]), 0),\n",
       "       (array([[ 0.        ,  0.        ,  0.        , ...,  0.10299776,\n",
       "        -0.001346  , -0.226027  ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.10025404,\n",
       "        -0.0125163 , -0.230909  ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.09391637,\n",
       "        -0.0240066 , -0.245108  ],\n",
       "       ..., \n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.0862923 ,\n",
       "         0.0006496 , -0.251447  ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.09493048,\n",
       "        -0.0351646 , -0.236531  ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.11232334,\n",
       "        -0.0043682 , -0.221527  ]]), 0)], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making test and train split\n",
    "#the recentering has been done so that the pelvic joint is always at the origin\n",
    "#labels are to be zero indexed\n",
    "def train_test_split(dframe_list):\n",
    "    train_split = np.empty(0, dtype=object)\n",
    "    test_split = np.empty(0, dtype=object)\n",
    "    for dframe in dframe_list:\n",
    "        label = dframe.iloc[0,75]-1\n",
    "#         print(label)\n",
    "        num_samples = len(dframe.iloc[:,:])\n",
    "        video_ids = np.unique(dframe.iloc[:,-1].values)\n",
    "        train_video_ids = video_ids[:-15]\n",
    "        test_video_ids = video_ids[-15:]\n",
    "        train_split1 = np.empty(len(train_video_ids), dtype=object)\n",
    "        test_split1 = np.empty(len(test_video_ids), dtype=object)\n",
    "        for idx,i in enumerate(train_video_ids):\n",
    "            train_split1[idx] = dframe.loc[dframe['video_id'] == i].values[:,0:75]\n",
    "            for fidx, f in enumerate(train_split1[idx]):\n",
    "                f = np.reshape(f, (25,3))\n",
    "                f = f-f[0,:]\n",
    "                f = np.reshape(f, (1,75))\n",
    "                train_split1[idx][fidx] = f\n",
    "#             mean_vec = np.mean(train_split1[idx], axis=0)\n",
    "#             std_vec = np.std(train_split1[idx], axis=0)\n",
    "            train_split1[idx] = (train_split1[idx], label)\n",
    "\n",
    "        for idx,i in enumerate(test_video_ids):\n",
    "            test_split1[idx] = dframe.loc[dframe['video_id'] == i].values[:,0:75]\n",
    "            for fidx, f in enumerate(test_split1[idx]):\n",
    "                f = np.reshape(f, (25,3))\n",
    "                f = f-f[0,:]\n",
    "                f = np.reshape(f, (1,75))\n",
    "                test_split1[idx][fidx] = f\n",
    "#             mean_vec = np.mean(test_split1[idx], axis=0)\n",
    "#             std_vec = np.std(test_split1[idx], axis=0)\n",
    "            test_split1[idx] = (test_split1[idx], label)\n",
    "        train_split = np.concatenate((train_split, train_split1))\n",
    "        test_split = np.concatenate((test_split, test_split1))\n",
    "    return train_split, test_split\n",
    "\n",
    "train_split, test_split = train_test_split([dframe, dframe2, dframe3, dframe4, dframe5, dframe6, dframe7])\n",
    "\n",
    "# #looking at split\n",
    "train_split[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.        ,  0.        ,  0.        , ...,  0.0268366 ,\n",
       "          0.09410502, -0.137822  ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.0259004 ,\n",
       "          0.09034627, -0.136465  ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.0274235 ,\n",
       "          0.09725001, -0.143871  ],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.0640166 ,\n",
       "          0.67424485,  0.093205  ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.0431631 ,\n",
       "          0.65304658,  0.119603  ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.047652  ,\n",
       "          0.65330377,  0.114809  ]]), 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEQ_LEN = None\n",
    "def Data_gen( train_split, SEQ_LEN):\n",
    "    while(True):\n",
    "        X = train_split\n",
    "        databatch = random.sample(list(X), 1)[0]\n",
    "#         print(databatch)\n",
    "        databatch, label = databatch[0], databatch[1]\n",
    "        if SEQ_LEN is not None:\n",
    "            if len(databatch) > SEQ_LEN:\n",
    "                databatch = databatch[0:SEQ_LEN]\n",
    "            elif len(databatch) < SEQ_LEN:\n",
    "                databatch = np.concatenate((databatch, np.zeros((SEQ_LEN - len(databatch), 75))))\n",
    "            else:\n",
    "                pass\n",
    "            yield databatch,label\n",
    "        else:\n",
    "            yield databatch,label\n",
    "\n",
    "ACTd = Data_gen(train_split, SEQ_LEN)\n",
    "\n",
    "#to look at batch created by Actd\n",
    "next(ACTd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Classifier model defination and intialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#action LSTM\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, joints_dim, hidden_dim, label_size, batch_size, num_layers, kernel_size):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        joints_dim2d = joints_dim - 25\n",
    "        \n",
    "        self.lstm3 = nn.LSTM(joints_dim, hidden_dim, num_layers=self.num_layers)\n",
    "        self.conv1_3 = nn.Conv1d(1, 1, kernel_size, stride=1, padding=1)\n",
    "        \n",
    "        self.lstm2_1 = nn.LSTM(joints_dim2d, hidden_dim, num_layers=self.num_layers)\n",
    "        self.conv1_2_1 = nn.Conv1d(1, 1, kernel_size, stride=1, padding=1)\n",
    "        self.lstm2_2 = nn.LSTM(joints_dim2d, hidden_dim, num_layers=self.num_layers)\n",
    "        self.conv1_2_2 = nn.Conv1d(1, 1, kernel_size, stride=1, padding=1)\n",
    "        self.lstm2_3 = nn.LSTM(joints_dim2d, hidden_dim, num_layers=self.num_layers)\n",
    "        self.conv1_2_3 = nn.Conv1d(1, 1, kernel_size, stride=1, padding=1)\n",
    "        \n",
    "#         self.conv1_1 = nn.Conv1d(4, 2, kernel_size, stride=1, padding=1) #for kernel size=3\n",
    "#         self.conv1_2 = nn.Conv1d(2, 1, kernel_size, stride=1, padding=1) #for kernel size=3\n",
    "        \n",
    "        self.hidden3 = self.init_hidden3()\n",
    "        self.hidden2_1 = self.init_hidden2_1()\n",
    "        self.hidden2_2 = self.init_hidden2_2()\n",
    "        self.hidden2_3 = self.init_hidden2_3()\n",
    "        \n",
    "        self.hidden2label = nn.Linear(hidden_dim, label_size)\n",
    "    \n",
    "    def init_hidden3(self):\n",
    "        # the first is the hidden h\n",
    "        # the second is the cell  c\n",
    "        return (autograd.Variable(torch.zeros(self.num_layers, self.batch_size, self.hidden_dim).cuda()),\n",
    "                autograd.Variable(torch.zeros(self.num_layers, self.batch_size, self.hidden_dim).cuda()))\n",
    "    def init_hidden2_1(self):\n",
    "        # the first is the hidden h\n",
    "        # the second is the cell  c\n",
    "        return (autograd.Variable(torch.zeros(self.num_layers, self.batch_size, self.hidden_dim).cuda()),\n",
    "                autograd.Variable(torch.zeros(self.num_layers, self.batch_size, self.hidden_dim).cuda()))\n",
    "    def init_hidden2_2(self):\n",
    "        # the first is the hidden h\n",
    "        # the second is the cell  c\n",
    "        return (autograd.Variable(torch.zeros(self.num_layers, self.batch_size, self.hidden_dim).cuda()),\n",
    "                autograd.Variable(torch.zeros(self.num_layers, self.batch_size, self.hidden_dim).cuda()))\n",
    "    def init_hidden2_3(self):\n",
    "        # the first is the hidden h\n",
    "        # the second is the cell  c\n",
    "        return (autograd.Variable(torch.zeros(self.num_layers, self.batch_size, self.hidden_dim).cuda()),\n",
    "                autograd.Variable(torch.zeros(self.num_layers, self.batch_size, self.hidden_dim).cuda()))\n",
    "    \n",
    "    \n",
    "    def forward(self, joints3d_vec):\n",
    "        x3 = joints3d_vec\n",
    "        x2 = x3.view(-1, 25, 3)\n",
    "        x2_1 = x2[:,:,1:3].contiguous().view(-1, 1, 50)\n",
    "        x2_2 = x2[:,:,0:2].contiguous().view(-1, 1, 50)\n",
    "        x2_3 = x2[:,:,[0,2]].contiguous().view(-1, 1, 50)\n",
    "#         print('x2_3 : ',x2_3.size())\n",
    "        lstm_out3, self.hidden3 = self.lstm3(x3, self.hidden3)\n",
    "        lstm_out2_1, self.hidden2_1 = self.lstm2_1(x2_1, self.hidden2_1)\n",
    "        lstm_out2_2, self.hidden2_2 = self.lstm2_2(x2_2, self.hidden2_2)\n",
    "        lstm_out2_3, self.hidden2_3 = self.lstm2_3(x2_3, self.hidden2_3)\n",
    "#         print('lstm_out[-1] : ', lstm_out[-1].size())\n",
    "        t3 = lstm_out3[-1].view(self.batch_size,1,-1)\n",
    "#         print('t3 : ', t3.size())\n",
    "        t2_1 = lstm_out2_1[-1].view(self.batch_size,1,-1)\n",
    "        t2_2 = lstm_out2_2[-1].view(self.batch_size,1,-1)\n",
    "        t2_3 = lstm_out2_3[-1].view(self.batch_size,1,-1)\n",
    "#         print('t2_3 : ', t2_3.size())\n",
    "        \n",
    "#         t = autograd.Variable(torch.zeros(self.batch_size, 4, self.hidden_dim).cuda())\n",
    "#         t[:,0,:] = t3\n",
    "#         t[:,1,:] = t2_1\n",
    "#         t[:,2,:] = t2_2\n",
    "#         t[:,3,:] = t2_3\n",
    "#         print('t : ', t.size())\n",
    "        \n",
    "        y3 = self.conv1_3(t3)\n",
    "#         print('y3 : ', y3.size())\n",
    "        y2_1 = self.conv1_2_1(t2_1)\n",
    "#         print('y2_1 : ', y2_1.size())\n",
    "        y2_2 = self.conv1_2_2(t2_2)\n",
    "#         print('y2_2 : ', y2_2.size())\n",
    "        y2_3 = self.conv1_2_3(t2_3)\n",
    "#         print('y2_3 : ', y2_3.size())\n",
    "        \n",
    "        y3 += y2_1+y2_2+y2_3\n",
    "        \n",
    "        y3 = y3.contiguous().view(-1, self.hidden_dim)\n",
    "#         print('y3 : ', y3.size())\n",
    "        \n",
    "        y  = self.hidden2label(y3)\n",
    "        log_probs = F.log_softmax(y, dim=1)\n",
    "        return log_probs\n",
    "#instanstiating a model\n",
    "model0 = LSTMClassifier(75, 512, 7, 1, 2, 3)\n",
    "#to do stuff in CUDA\n",
    "model0 = model0.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(model, test_split):\n",
    "    pred_labels = np.empty(len(test_split))\n",
    "    orig_labels = np.array([t[1] for t in test_split])\n",
    "    for i in range(len(test_split)):\n",
    "        d_in = autograd.Variable(torch.from_numpy(test_split[i][0]).float().cuda())\n",
    "        d_in = d_in.view(d_in.size()[0], 1, -1)\n",
    "        y_pred = model(d_in)\n",
    "        pred_labels[i] = y_pred.data.cpu().max(1)[1].numpy()[0];\n",
    "    n_samples = len(pred_labels)\n",
    "    res=(orig_labels==pred_labels)\n",
    "    correct_count = (res==True).sum()\n",
    "    return (correct_count*100/n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## observations\n",
    "* better to use the log_softmax instead of softmax\n",
    "* decrease lr succicesively to get better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the training ...\n",
      "epoch 0 starting ...\n",
      "epoch: 0 iterations: 0 loss :3.15954\n",
      "epoch: 0 iterations: 100 loss :0.879976\n",
      "epoch: 0 iterations: 200 loss :0.614032\n",
      "epoch: 0 iterations: 300 loss :7.34364\n",
      "epoch: 0 iterations: 400 loss :0.50641\n",
      "epoch: 0 iterations: 500 loss :0.553741\n",
      "epoch: 0 iterations: 600 loss :1.75925\n",
      "epoch: 0 iterations: 700 loss :0.0195188\n",
      "epoch: 0 iterations: 800 loss :2.65247\n",
      "epoch: 0 iterations: 900 loss :0.0165366\n",
      "epoch: 0 <====train track===> avg_loss: 0.007322494991155901, accuracy: 76.19047619047619% \n",
      "\n",
      "epoch 1 starting ...\n",
      "epoch: 1 iterations: 0 loss :2.06688\n",
      "epoch: 1 iterations: 100 loss :0.0764818\n",
      "epoch: 1 iterations: 200 loss :0.969443\n",
      "epoch: 1 iterations: 300 loss :0.0545608\n",
      "epoch: 1 iterations: 400 loss :0.468019\n",
      "epoch: 1 iterations: 500 loss :0.727475\n",
      "epoch: 1 iterations: 600 loss :0.983347\n",
      "epoch: 1 iterations: 700 loss :1.065\n",
      "epoch: 1 iterations: 800 loss :0.301212\n",
      "epoch: 1 iterations: 900 loss :0.108769\n",
      "epoch: 1 <====train track===> avg_loss: 0.007140260845138711, accuracy: 76.19047619047619% \n",
      "\n",
      "epoch 2 starting ...\n",
      "epoch: 2 iterations: 0 loss :0.265581\n",
      "epoch: 2 iterations: 100 loss :0.51753\n",
      "epoch: 2 iterations: 200 loss :0.382018\n",
      "epoch: 2 iterations: 300 loss :1.39139\n",
      "epoch: 2 iterations: 400 loss :0.17367\n",
      "epoch: 2 iterations: 500 loss :1.0308\n",
      "epoch: 2 iterations: 600 loss :0.060106\n",
      "epoch: 2 iterations: 700 loss :0.256803\n",
      "epoch: 2 iterations: 800 loss :1.16017\n",
      "epoch: 2 iterations: 900 loss :1.28391\n",
      "epoch: 2 <====train track===> avg_loss: 0.007155734613511, accuracy: 77.14285714285714% \n",
      "\n",
      "epoch 3 starting ...\n",
      "epoch: 3 iterations: 0 loss :1.24887\n",
      "epoch: 3 iterations: 100 loss :0.160603\n",
      "epoch: 3 iterations: 200 loss :0.334022\n",
      "epoch: 3 iterations: 300 loss :0.0434275\n",
      "epoch: 3 iterations: 400 loss :3.25849\n",
      "epoch: 3 iterations: 500 loss :0.0262283\n",
      "epoch: 3 iterations: 600 loss :0.686445\n",
      "epoch: 3 iterations: 700 loss :1.2192\n",
      "epoch: 3 iterations: 800 loss :0.0168312\n",
      "epoch: 3 iterations: 900 loss :0.0414603\n",
      "epoch: 3 <====train track===> avg_loss: 0.007268846978191834, accuracy: 78.0952380952381% \n",
      "\n",
      "epoch 4 starting ...\n",
      "epoch: 4 iterations: 0 loss :0.00507709\n",
      "epoch: 4 iterations: 100 loss :0.000653173\n",
      "epoch: 4 iterations: 200 loss :0.00166242\n",
      "epoch: 4 iterations: 300 loss :0.0366673\n",
      "epoch: 4 iterations: 400 loss :0.00159994\n",
      "epoch: 4 iterations: 500 loss :0.861556\n",
      "epoch: 4 iterations: 600 loss :0.0112399\n",
      "epoch: 4 iterations: 700 loss :0.00823412\n",
      "epoch: 4 iterations: 800 loss :1.86282\n",
      "epoch: 4 iterations: 900 loss :0.0430142\n",
      "epoch: 4 <====train track===> avg_loss: 0.006834484084965555, accuracy: 80.95238095238095% \n",
      "\n",
      "epoch 5 starting ...\n",
      "epoch: 5 iterations: 0 loss :0.0194083\n",
      "epoch: 5 iterations: 100 loss :1.48908\n",
      "epoch: 5 iterations: 200 loss :0.0253633\n",
      "epoch: 5 iterations: 300 loss :0.651308\n",
      "epoch: 5 iterations: 400 loss :0.0578307\n",
      "epoch: 5 iterations: 500 loss :0.117866\n",
      "epoch: 5 iterations: 600 loss :0.90344\n",
      "epoch: 5 iterations: 700 loss :1.91046\n",
      "epoch: 5 iterations: 800 loss :0.00875267\n",
      "epoch: 5 iterations: 900 loss :1.6683\n",
      "epoch: 5 <====train track===> avg_loss: 0.0071532973426326404, accuracy: 77.14285714285714% \n",
      "\n",
      "epoch 6 starting ...\n",
      "epoch: 6 iterations: 0 loss :1.20665\n",
      "epoch: 6 iterations: 100 loss :0.212488\n",
      "epoch: 6 iterations: 200 loss :0.451165\n",
      "epoch: 6 iterations: 300 loss :0.88602\n",
      "epoch: 6 iterations: 400 loss :0.0623371\n",
      "epoch: 6 iterations: 500 loss :0.0637495\n",
      "epoch: 6 iterations: 600 loss :0.0868138\n",
      "epoch: 6 iterations: 700 loss :2.82052\n",
      "epoch: 6 iterations: 800 loss :0.282475\n",
      "epoch: 6 iterations: 900 loss :0.00159411\n",
      "epoch: 6 <====train track===> avg_loss: 0.00726967526478002, accuracy: 78.0952380952381% \n",
      "\n",
      "epoch 7 starting ...\n",
      "epoch: 7 iterations: 0 loss :0.526988\n",
      "epoch: 7 iterations: 100 loss :0.2992\n",
      "epoch: 7 iterations: 200 loss :0.00336414\n",
      "epoch: 7 iterations: 300 loss :2.68642\n",
      "epoch: 7 iterations: 400 loss :0.0204702\n",
      "epoch: 7 iterations: 500 loss :3.17351\n",
      "epoch: 7 iterations: 600 loss :0.124704\n",
      "epoch: 7 iterations: 700 loss :0.0249268\n",
      "epoch: 7 iterations: 800 loss :0.000554646\n",
      "epoch: 7 iterations: 900 loss :1.43242\n",
      "epoch: 7 <====train track===> avg_loss: 0.007019877861227645, accuracy: 79.04761904761905% \n",
      "\n",
      "epoch 8 starting ...\n",
      "epoch: 8 iterations: 0 loss :3.13603\n",
      "epoch: 8 iterations: 100 loss :0.0626587\n",
      "epoch: 8 iterations: 200 loss :2.58251\n",
      "epoch: 8 iterations: 300 loss :0.00123044\n",
      "epoch: 8 iterations: 400 loss :0.000838286\n",
      "epoch: 8 iterations: 500 loss :2.92294\n",
      "epoch: 8 iterations: 600 loss :0.0791501\n",
      "epoch: 8 iterations: 700 loss :0.00216512\n",
      "epoch: 8 iterations: 800 loss :0.586836\n",
      "epoch: 8 iterations: 900 loss :0.456436\n",
      "epoch: 8 <====train track===> avg_loss: 0.006685057604925814, accuracy: 80.0% \n",
      "\n",
      "epoch 9 starting ...\n",
      "epoch: 9 iterations: 0 loss :0.485565\n",
      "epoch: 9 iterations: 100 loss :0.463062\n",
      "epoch: 9 iterations: 200 loss :1.37549\n",
      "epoch: 9 iterations: 300 loss :0.380466\n",
      "epoch: 9 iterations: 400 loss :1.2591\n",
      "epoch: 9 iterations: 500 loss :0.00544778\n",
      "epoch: 9 iterations: 600 loss :0.18054\n",
      "epoch: 9 iterations: 700 loss :0.611773\n",
      "epoch: 9 iterations: 800 loss :0.184695\n",
      "epoch: 9 iterations: 900 loss :0.0142865\n",
      "epoch: 9 <====train track===> avg_loss: 0.006551264500653747, accuracy: 80.95238095238095% \n",
      "\n",
      "epoch 10 starting ...\n",
      "epoch: 10 iterations: 0 loss :0.378401\n",
      "epoch: 10 iterations: 100 loss :0.300394\n",
      "epoch: 10 iterations: 200 loss :0.00612004\n",
      "epoch: 10 iterations: 300 loss :1.34341\n",
      "epoch: 10 iterations: 400 loss :0.00277171\n",
      "epoch: 10 iterations: 500 loss :1.51028\n",
      "epoch: 10 iterations: 600 loss :0.174781\n",
      "epoch: 10 iterations: 700 loss :1.31251\n",
      "epoch: 10 iterations: 800 loss :1.80999\n",
      "epoch: 10 iterations: 900 loss :0.289202\n",
      "epoch: 10 <====train track===> avg_loss: 0.006993671024604738, accuracy: 80.95238095238095% \n",
      "\n",
      "epoch 11 starting ...\n",
      "epoch: 11 iterations: 0 loss :0.305013\n",
      "epoch: 11 iterations: 100 loss :1.75167\n",
      "epoch: 11 iterations: 200 loss :0.000528792\n",
      "epoch: 11 iterations: 300 loss :1.2179\n",
      "epoch: 11 iterations: 400 loss :0.0301815\n",
      "epoch: 11 iterations: 500 loss :0.136388\n",
      "epoch: 11 iterations: 600 loss :0.0417758\n",
      "epoch: 11 iterations: 700 loss :0.185349\n",
      "epoch: 11 iterations: 800 loss :0.529939\n",
      "epoch: 11 iterations: 900 loss :1.50836\n",
      "epoch: 11 <====train track===> avg_loss: 0.007249568060559279, accuracy: 80.0% \n",
      "\n",
      "epoch 12 starting ...\n",
      "epoch: 12 iterations: 0 loss :0.093595\n",
      "epoch: 12 iterations: 100 loss :0.25552\n",
      "epoch: 12 iterations: 200 loss :0.203177\n",
      "epoch: 12 iterations: 300 loss :0.583992\n",
      "epoch: 12 iterations: 400 loss :0.643392\n",
      "epoch: 12 iterations: 500 loss :0.911262\n",
      "epoch: 12 iterations: 600 loss :0.00361028\n",
      "epoch: 12 iterations: 700 loss :0.0452251\n",
      "epoch: 12 iterations: 800 loss :0.00490011\n",
      "epoch: 12 iterations: 900 loss :0.916497\n",
      "epoch: 12 <====train track===> avg_loss: 0.006574247300336236, accuracy: 80.95238095238095% \n",
      "\n",
      "epoch 13 starting ...\n",
      "epoch: 13 iterations: 0 loss :0.0174216\n",
      "epoch: 13 iterations: 100 loss :0.00044622\n",
      "epoch: 13 iterations: 200 loss :0.131245\n",
      "epoch: 13 iterations: 300 loss :0.0051339\n",
      "epoch: 13 iterations: 400 loss :0.493605\n",
      "epoch: 13 iterations: 500 loss :0.549442\n",
      "epoch: 13 iterations: 600 loss :0.0193984\n",
      "epoch: 13 iterations: 700 loss :0.12997\n",
      "epoch: 13 iterations: 800 loss :0.564086\n",
      "epoch: 13 iterations: 900 loss :0.166724\n",
      "epoch: 13 <====train track===> avg_loss: 0.006531819453179542, accuracy: 80.0% \n",
      "\n",
      "epoch 14 starting ...\n",
      "epoch: 14 iterations: 0 loss :0.081124\n",
      "epoch: 14 iterations: 100 loss :0.043679\n",
      "epoch: 14 iterations: 200 loss :0.862471\n",
      "epoch: 14 iterations: 300 loss :0.568276\n",
      "epoch: 14 iterations: 400 loss :0.593985\n",
      "epoch: 14 iterations: 500 loss :0.0482446\n",
      "epoch: 14 iterations: 600 loss :1.09756\n",
      "epoch: 14 iterations: 700 loss :2.17877\n",
      "epoch: 14 iterations: 800 loss :0.330582\n",
      "epoch: 14 iterations: 900 loss :0.77602\n",
      "epoch: 14 <====train track===> avg_loss: 0.006059851425329882, accuracy: 81.9047619047619% \n",
      "\n",
      "epoch 15 starting ...\n",
      "epoch: 15 iterations: 0 loss :3.34983\n",
      "epoch: 15 iterations: 100 loss :0.0231565\n",
      "epoch: 15 iterations: 200 loss :0.00743811\n",
      "epoch: 15 iterations: 300 loss :1.43654\n",
      "epoch: 15 iterations: 400 loss :0.464983\n",
      "epoch: 15 iterations: 500 loss :0.0466021\n",
      "epoch: 15 iterations: 600 loss :0.0480204\n",
      "epoch: 15 iterations: 700 loss :1.27556\n",
      "epoch: 15 iterations: 800 loss :1.51867\n",
      "epoch: 15 iterations: 900 loss :0.00460077\n",
      "epoch: 15 <====train track===> avg_loss: 0.006853308848375885, accuracy: 80.0% \n",
      "\n",
      "epoch 16 starting ...\n",
      "epoch: 16 iterations: 0 loss :0.129739\n",
      "epoch: 16 iterations: 100 loss :2.65682\n",
      "epoch: 16 iterations: 200 loss :0.0572946\n",
      "epoch: 16 iterations: 300 loss :0.0585691\n",
      "epoch: 16 iterations: 400 loss :0.443042\n",
      "epoch: 16 iterations: 500 loss :0.0324155\n",
      "epoch: 16 iterations: 600 loss :0.816954\n",
      "epoch: 16 iterations: 700 loss :0.073058\n",
      "epoch: 16 iterations: 800 loss :0.0365441\n",
      "epoch: 16 iterations: 900 loss :0.000858296\n",
      "epoch: 16 <====train track===> avg_loss: 0.006722919698177238, accuracy: 80.95238095238095% \n",
      "\n",
      "epoch 17 starting ...\n",
      "epoch: 17 iterations: 0 loss :5.65104\n",
      "epoch: 17 iterations: 100 loss :0.00777871\n",
      "epoch: 17 iterations: 200 loss :0.000374843\n",
      "epoch: 17 iterations: 300 loss :1.77289\n",
      "epoch: 17 iterations: 400 loss :0.389552\n",
      "epoch: 17 iterations: 500 loss :0.28273\n",
      "epoch: 17 iterations: 600 loss :0.0395211\n",
      "epoch: 17 iterations: 700 loss :1.06821\n",
      "epoch: 17 iterations: 800 loss :0.100602\n",
      "epoch: 17 iterations: 900 loss :1.75075\n",
      "epoch: 17 <====train track===> avg_loss: 0.0069520733673593405, accuracy: 80.95238095238095% \n",
      "\n",
      "epoch 18 starting ...\n",
      "epoch: 18 iterations: 0 loss :0.488965\n",
      "epoch: 18 iterations: 100 loss :1.11381\n",
      "epoch: 18 iterations: 200 loss :0.139729\n",
      "epoch: 18 iterations: 300 loss :4.63862\n",
      "epoch: 18 iterations: 400 loss :0.897016\n",
      "epoch: 18 iterations: 500 loss :2.40176\n",
      "epoch: 18 iterations: 600 loss :0.0356587\n",
      "epoch: 18 iterations: 700 loss :0.279916\n",
      "epoch: 18 iterations: 800 loss :0.508083\n",
      "epoch: 18 iterations: 900 loss :0.00991196\n",
      "epoch: 18 <====train track===> avg_loss: 0.0068882407747820505, accuracy: 81.9047619047619% \n",
      "\n",
      "epoch 19 starting ...\n",
      "epoch: 19 iterations: 0 loss :0.347773\n",
      "epoch: 19 iterations: 100 loss :0.210474\n",
      "epoch: 19 iterations: 200 loss :0.290227\n",
      "epoch: 19 iterations: 300 loss :0.21386\n",
      "epoch: 19 iterations: 400 loss :0.0190907\n",
      "epoch: 19 iterations: 500 loss :0.0197099\n",
      "epoch: 19 iterations: 600 loss :0.825395\n",
      "epoch: 19 iterations: 700 loss :0.128688\n",
      "epoch: 19 iterations: 800 loss :0.182742\n",
      "epoch: 19 iterations: 900 loss :0.529224\n",
      "epoch: 19 <====train track===> avg_loss: 0.006838863518502935, accuracy: 81.9047619047619% \n",
      "\n",
      "epoch 20 starting ...\n",
      "epoch: 20 iterations: 0 loss :0.810898\n",
      "epoch: 20 iterations: 100 loss :0.00234519\n",
      "epoch: 20 iterations: 200 loss :0.0258807\n",
      "epoch: 20 iterations: 300 loss :1.81189\n",
      "epoch: 20 iterations: 400 loss :1.08946\n",
      "epoch: 20 iterations: 500 loss :0.00474067\n",
      "epoch: 20 iterations: 600 loss :1.54637\n",
      "epoch: 20 iterations: 700 loss :0.33744\n",
      "epoch: 20 iterations: 800 loss :0.718457\n",
      "epoch: 20 iterations: 900 loss :0.155342\n",
      "epoch: 20 <====train track===> avg_loss: 0.0067013127417030515, accuracy: 82.85714285714286% \n",
      "\n",
      "epoch 21 starting ...\n",
      "epoch: 21 iterations: 0 loss :0.340347\n",
      "epoch: 21 iterations: 100 loss :0.137354\n",
      "epoch: 21 iterations: 200 loss :0.133102\n",
      "epoch: 21 iterations: 300 loss :2.59072\n",
      "epoch: 21 iterations: 400 loss :0.458247\n",
      "epoch: 21 iterations: 500 loss :0.0503732\n",
      "epoch: 21 iterations: 600 loss :1.36195\n",
      "epoch: 21 iterations: 700 loss :0.822824\n",
      "epoch: 21 iterations: 800 loss :0.0152957\n",
      "epoch: 21 iterations: 900 loss :0.0110455\n",
      "epoch: 21 <====train track===> avg_loss: 0.00612189993640027, accuracy: 83.80952380952381% \n",
      "\n",
      "epoch 22 starting ...\n",
      "epoch: 22 iterations: 0 loss :0.000630299\n",
      "epoch: 22 iterations: 100 loss :0.0477854\n",
      "epoch: 22 iterations: 200 loss :0.0243876\n",
      "epoch: 22 iterations: 300 loss :1.69382\n",
      "epoch: 22 iterations: 400 loss :0.913135\n",
      "epoch: 22 iterations: 500 loss :0.118841\n",
      "epoch: 22 iterations: 600 loss :0.0236843\n",
      "epoch: 22 iterations: 700 loss :2.01879\n",
      "epoch: 22 iterations: 800 loss :0.0954771\n",
      "epoch: 22 iterations: 900 loss :0.274672\n",
      "epoch: 22 <====train track===> avg_loss: 0.006423197408062408, accuracy: 82.85714285714286% \n",
      "\n",
      "epoch 23 starting ...\n",
      "epoch: 23 iterations: 0 loss :0.0232409\n",
      "epoch: 23 iterations: 100 loss :0.00102813\n",
      "epoch: 23 iterations: 200 loss :0.0874483\n",
      "epoch: 23 iterations: 300 loss :0.0153018\n",
      "epoch: 23 iterations: 400 loss :1.60539\n",
      "epoch: 23 iterations: 500 loss :0.00124746\n",
      "epoch: 23 iterations: 600 loss :0.00187067\n",
      "epoch: 23 iterations: 700 loss :0.212652\n",
      "epoch: 23 iterations: 800 loss :0.00524407\n",
      "epoch: 23 iterations: 900 loss :0.000960127\n",
      "epoch: 23 <====train track===> avg_loss: 0.006529826048850186, accuracy: 82.85714285714286% \n",
      "\n",
      "epoch 24 starting ...\n",
      "epoch: 24 iterations: 0 loss :0.000999071\n",
      "epoch: 24 iterations: 100 loss :0.683004\n",
      "epoch: 24 iterations: 200 loss :0.957074\n",
      "epoch: 24 iterations: 300 loss :0.1332\n",
      "epoch: 24 iterations: 400 loss :1.5285\n",
      "epoch: 24 iterations: 500 loss :1.44887\n",
      "epoch: 24 iterations: 600 loss :0.620852\n",
      "epoch: 24 iterations: 700 loss :0.0766823\n",
      "epoch: 24 iterations: 800 loss :0.219487\n",
      "epoch: 24 iterations: 900 loss :0.871613\n",
      "epoch: 24 <====train track===> avg_loss: 0.006788842440223544, accuracy: 83.80952380952381% \n",
      "\n",
      "epoch 25 starting ...\n",
      "epoch: 25 iterations: 0 loss :0.00533229\n",
      "epoch: 25 iterations: 100 loss :0.0579789\n",
      "epoch: 25 iterations: 200 loss :0.91557\n",
      "epoch: 25 iterations: 300 loss :0.225998\n",
      "epoch: 25 iterations: 400 loss :0.112334\n",
      "epoch: 25 iterations: 500 loss :0.377978\n",
      "epoch: 25 iterations: 600 loss :1.11247\n",
      "epoch: 25 iterations: 700 loss :0.00162815\n",
      "epoch: 25 iterations: 800 loss :0.000906176\n",
      "epoch: 25 iterations: 900 loss :0.726211\n",
      "epoch: 25 <====train track===> avg_loss: 0.006537509056222603, accuracy: 81.9047619047619% \n",
      "\n",
      "epoch 26 starting ...\n",
      "epoch: 26 iterations: 0 loss :0.0457008\n",
      "epoch: 26 iterations: 100 loss :0.950528\n",
      "epoch: 26 iterations: 200 loss :0.688023\n",
      "epoch: 26 iterations: 300 loss :0.115791\n",
      "epoch: 26 iterations: 400 loss :2.54216\n",
      "epoch: 26 iterations: 500 loss :0.0306887\n",
      "epoch: 26 iterations: 600 loss :0.00672778\n",
      "epoch: 26 iterations: 700 loss :0.378222\n",
      "epoch: 26 iterations: 800 loss :0.403127\n",
      "epoch: 26 iterations: 900 loss :0.449662\n",
      "epoch: 26 <====train track===> avg_loss: 0.0065734245324427345, accuracy: 80.0% \n",
      "\n",
      "epoch 27 starting ...\n",
      "epoch: 27 iterations: 0 loss :0.0598762\n",
      "epoch: 27 iterations: 100 loss :0.203212\n",
      "epoch: 27 iterations: 200 loss :0.0103557\n",
      "epoch: 27 iterations: 300 loss :1.64152\n",
      "epoch: 27 iterations: 400 loss :0.0719635\n",
      "epoch: 27 iterations: 500 loss :0.196454\n",
      "epoch: 27 iterations: 600 loss :0.955618\n",
      "epoch: 27 iterations: 700 loss :0.631747\n",
      "epoch: 27 iterations: 800 loss :0.869972\n",
      "epoch: 27 iterations: 900 loss :0.10327\n",
      "epoch: 27 <====train track===> avg_loss: 0.0064044530643446425, accuracy: 84.76190476190476% \n",
      "\n",
      "epoch 28 starting ...\n",
      "epoch: 28 iterations: 0 loss :1.07339\n",
      "epoch: 28 iterations: 100 loss :0.0555294\n",
      "epoch: 28 iterations: 200 loss :0.944762\n",
      "epoch: 28 iterations: 300 loss :0.267309\n",
      "epoch: 28 iterations: 400 loss :0.320846\n",
      "epoch: 28 iterations: 500 loss :0.336808\n",
      "epoch: 28 iterations: 600 loss :1.88024\n",
      "epoch: 28 iterations: 700 loss :0.487602\n",
      "epoch: 28 iterations: 800 loss :0.065362\n",
      "epoch: 28 iterations: 900 loss :0.205222\n",
      "epoch: 28 <====train track===> avg_loss: 0.006348875582321633, accuracy: 83.80952380952381% \n",
      "\n",
      "epoch 29 starting ...\n",
      "epoch: 29 iterations: 0 loss :0.0118564\n",
      "epoch: 29 iterations: 100 loss :0.482164\n",
      "epoch: 29 iterations: 200 loss :1.07778\n",
      "epoch: 29 iterations: 300 loss :1.60732\n",
      "epoch: 29 iterations: 400 loss :0.000728104\n",
      "epoch: 29 iterations: 500 loss :0.00253701\n",
      "epoch: 29 iterations: 600 loss :0.174574\n",
      "epoch: 29 iterations: 700 loss :0.88778\n",
      "epoch: 29 iterations: 800 loss :0.100237\n",
      "epoch: 29 iterations: 900 loss :4.28318\n",
      "epoch: 29 <====train track===> avg_loss: 0.006246077279377969, accuracy: 84.76190476190476% \n",
      "\n",
      "epoch 30 starting ...\n",
      "epoch: 30 iterations: 0 loss :0.548683\n",
      "epoch: 30 iterations: 100 loss :0.000236126\n",
      "epoch: 30 iterations: 200 loss :0.810649\n",
      "epoch: 30 iterations: 300 loss :0.00397392\n",
      "epoch: 30 iterations: 400 loss :0.135808\n",
      "epoch: 30 iterations: 500 loss :2.18345\n",
      "epoch: 30 iterations: 600 loss :0.0097251\n",
      "epoch: 30 iterations: 700 loss :0.0196982\n",
      "epoch: 30 iterations: 800 loss :0.288391\n",
      "epoch: 30 iterations: 900 loss :0.293677\n",
      "epoch: 30 <====train track===> avg_loss: 0.006463375860379986, accuracy: 83.80952380952381% \n",
      "\n",
      "epoch 31 starting ...\n",
      "epoch: 31 iterations: 0 loss :0.0223559\n",
      "epoch: 31 iterations: 100 loss :0.784019\n",
      "epoch: 31 iterations: 200 loss :0.00129401\n",
      "epoch: 31 iterations: 300 loss :0.165046\n",
      "epoch: 31 iterations: 400 loss :0.127876\n",
      "epoch: 31 iterations: 500 loss :0.0936886\n",
      "epoch: 31 iterations: 600 loss :1.61342\n",
      "epoch: 31 iterations: 700 loss :0.00562821\n",
      "epoch: 31 iterations: 800 loss :0.045472\n",
      "epoch: 31 iterations: 900 loss :0.189671\n",
      "epoch: 31 <====train track===> avg_loss: 0.006581640882477249, accuracy: 82.85714285714286% \n",
      "\n",
      "epoch 32 starting ...\n",
      "epoch: 32 iterations: 0 loss :0.13246\n",
      "epoch: 32 iterations: 100 loss :0.0291464\n",
      "epoch: 32 iterations: 200 loss :1.42688\n",
      "epoch: 32 iterations: 300 loss :0.328389\n",
      "epoch: 32 iterations: 400 loss :2.67624\n",
      "epoch: 32 iterations: 500 loss :0.0466698\n",
      "epoch: 32 iterations: 600 loss :0.00860164\n",
      "epoch: 32 iterations: 700 loss :0.0613134\n",
      "epoch: 32 iterations: 800 loss :0.0457365\n",
      "epoch: 32 iterations: 900 loss :0.00243629\n",
      "epoch: 32 <====train track===> avg_loss: 0.006795481413581734, accuracy: 83.80952380952381% \n",
      "\n",
      "epoch 33 starting ...\n",
      "epoch: 33 iterations: 0 loss :0.0238361\n",
      "epoch: 33 iterations: 100 loss :0.0743492\n",
      "epoch: 33 iterations: 200 loss :0.735846\n",
      "epoch: 33 iterations: 300 loss :0.466139\n",
      "epoch: 33 iterations: 400 loss :1.10424\n",
      "epoch: 33 iterations: 500 loss :0.0220317\n",
      "epoch: 33 iterations: 600 loss :0.0390645\n",
      "epoch: 33 iterations: 700 loss :0.0408571\n",
      "epoch: 33 iterations: 800 loss :0.287005\n",
      "epoch: 33 iterations: 900 loss :0.305207\n",
      "epoch: 33 <====train track===> avg_loss: 0.0064316975453282505, accuracy: 81.9047619047619% \n",
      "\n",
      "epoch 34 starting ...\n",
      "epoch: 34 iterations: 0 loss :0.823107\n",
      "epoch: 34 iterations: 100 loss :0.752406\n",
      "epoch: 34 iterations: 200 loss :0.710038\n",
      "epoch: 34 iterations: 300 loss :0.00575742\n",
      "epoch: 34 iterations: 400 loss :0.103014\n",
      "epoch: 34 iterations: 500 loss :0.0113382\n",
      "epoch: 34 iterations: 600 loss :1.08432\n",
      "epoch: 34 iterations: 700 loss :0.00525617\n",
      "epoch: 34 iterations: 800 loss :0.237069\n",
      "epoch: 34 iterations: 900 loss :0.00555341\n",
      "epoch: 34 <====train track===> avg_loss: 0.006459619488870054, accuracy: 85.71428571428571% \n",
      "\n",
      "epoch 35 starting ...\n",
      "epoch: 35 iterations: 0 loss :0.00128782\n",
      "epoch: 35 iterations: 100 loss :0.0371215\n",
      "epoch: 35 iterations: 200 loss :0.00222423\n",
      "epoch: 35 iterations: 300 loss :4.93849\n",
      "epoch: 35 iterations: 400 loss :1.45287\n",
      "epoch: 35 iterations: 500 loss :0.337912\n",
      "epoch: 35 iterations: 600 loss :0.345606\n",
      "epoch: 35 iterations: 700 loss :0.0392042\n",
      "epoch: 35 iterations: 800 loss :0.00090558\n",
      "epoch: 35 iterations: 900 loss :0.0145537\n",
      "epoch: 35 <====train track===> avg_loss: 0.006221537708192981, accuracy: 83.80952380952381% \n",
      "\n",
      "epoch 36 starting ...\n",
      "epoch: 36 iterations: 0 loss :1.27342\n",
      "epoch: 36 iterations: 100 loss :0.568837\n",
      "epoch: 36 iterations: 200 loss :1.2615\n",
      "epoch: 36 iterations: 300 loss :0.00265912\n",
      "epoch: 36 iterations: 400 loss :1.97806\n",
      "epoch: 36 iterations: 500 loss :1.20324\n",
      "epoch: 36 iterations: 600 loss :0.272513\n",
      "epoch: 36 iterations: 700 loss :0.0998399\n",
      "epoch: 36 iterations: 800 loss :0.560899\n",
      "epoch: 36 iterations: 900 loss :1.10463\n",
      "epoch: 36 <====train track===> avg_loss: 0.0064279960630601604, accuracy: 83.80952380952381% \n",
      "\n",
      "epoch 37 starting ...\n",
      "epoch: 37 iterations: 0 loss :0.0161703\n",
      "epoch: 37 iterations: 100 loss :2.42007\n",
      "epoch: 37 iterations: 200 loss :0.00500687\n",
      "epoch: 37 iterations: 300 loss :1.5964\n",
      "epoch: 37 iterations: 400 loss :0.129043\n",
      "epoch: 37 iterations: 500 loss :0.555321\n",
      "epoch: 37 iterations: 600 loss :0.198907\n",
      "epoch: 37 iterations: 700 loss :0.965445\n",
      "epoch: 37 iterations: 800 loss :0.0474632\n",
      "epoch: 37 iterations: 900 loss :0.528873\n",
      "epoch: 37 <====train track===> avg_loss: 0.006540803104579737, accuracy: 84.76190476190476% \n",
      "\n",
      "epoch 38 starting ...\n",
      "epoch: 38 iterations: 0 loss :0.310926\n",
      "epoch: 38 iterations: 100 loss :0.00162648\n",
      "epoch: 38 iterations: 200 loss :0.00268314\n",
      "epoch: 38 iterations: 300 loss :0.416819\n",
      "epoch: 38 iterations: 400 loss :0.00263154\n",
      "epoch: 38 iterations: 500 loss :0.122143\n",
      "epoch: 38 iterations: 600 loss :0.0713931\n",
      "epoch: 38 iterations: 700 loss :2.16812\n",
      "epoch: 38 iterations: 800 loss :0.462828\n",
      "epoch: 38 iterations: 900 loss :2.39206\n",
      "epoch: 38 <====train track===> avg_loss: 0.006447323551679446, accuracy: 82.85714285714286% \n",
      "\n",
      "epoch 39 starting ...\n",
      "epoch: 39 iterations: 0 loss :0.127804\n",
      "epoch: 39 iterations: 100 loss :4.37204\n",
      "epoch: 39 iterations: 200 loss :0.00770691\n",
      "epoch: 39 iterations: 300 loss :0.404894\n",
      "epoch: 39 iterations: 400 loss :1.5208\n",
      "epoch: 39 iterations: 500 loss :0.10203\n",
      "epoch: 39 iterations: 600 loss :2.07326\n",
      "epoch: 39 iterations: 700 loss :0.50581\n",
      "epoch: 39 iterations: 800 loss :0.000478153\n",
      "epoch: 39 iterations: 900 loss :0.48785\n",
      "epoch: 39 <====train track===> avg_loss: 0.006824023495446635, accuracy: 84.76190476190476% \n",
      "\n",
      "epoch 40 starting ...\n",
      "epoch: 40 iterations: 0 loss :0.00189601\n",
      "epoch: 40 iterations: 100 loss :0.0172404\n",
      "epoch: 40 iterations: 200 loss :0.346791\n",
      "epoch: 40 iterations: 300 loss :0.59777\n",
      "epoch: 40 iterations: 400 loss :0.428305\n",
      "epoch: 40 iterations: 500 loss :0.302806\n",
      "epoch: 40 iterations: 600 loss :0.228919\n",
      "epoch: 40 iterations: 700 loss :0.0259505\n",
      "epoch: 40 iterations: 800 loss :0.351598\n",
      "epoch: 40 iterations: 900 loss :0.0150952\n",
      "epoch: 40 <====train track===> avg_loss: 0.006367504974237974, accuracy: 85.71428571428571% \n",
      "\n",
      "epoch 41 starting ...\n",
      "epoch: 41 iterations: 0 loss :0.254352\n",
      "epoch: 41 iterations: 100 loss :0.00373927\n",
      "epoch: 41 iterations: 200 loss :0.479897\n",
      "epoch: 41 iterations: 300 loss :0.888864\n",
      "epoch: 41 iterations: 400 loss :0.462601\n",
      "epoch: 41 iterations: 500 loss :0.00218391\n",
      "epoch: 41 iterations: 600 loss :0.431044\n",
      "epoch: 41 iterations: 700 loss :0.617155\n",
      "epoch: 41 iterations: 800 loss :1.63071\n",
      "epoch: 41 iterations: 900 loss :0.0912568\n",
      "epoch: 41 <====train track===> avg_loss: 0.006672234318644533, accuracy: 83.80952380952381% \n",
      "\n",
      "epoch 42 starting ...\n",
      "epoch: 42 iterations: 0 loss :0.0441102\n",
      "epoch: 42 iterations: 100 loss :0.319876\n",
      "epoch: 42 iterations: 200 loss :0.222244\n",
      "epoch: 42 iterations: 300 loss :2.34095\n",
      "epoch: 42 iterations: 400 loss :0.76719\n",
      "epoch: 42 iterations: 500 loss :3.05782\n",
      "epoch: 42 iterations: 600 loss :0.278427\n",
      "epoch: 42 iterations: 700 loss :0.225686\n",
      "epoch: 42 iterations: 800 loss :0.0200765\n",
      "epoch: 42 iterations: 900 loss :1.07885\n",
      "epoch: 42 <====train track===> avg_loss: 0.007145914476332042, accuracy: 86.66666666666667% \n",
      "\n",
      "epoch 43 starting ...\n",
      "epoch: 43 iterations: 0 loss :0.118325\n",
      "epoch: 43 iterations: 100 loss :0.0773288\n",
      "epoch: 43 iterations: 200 loss :0.707305\n",
      "epoch: 43 iterations: 300 loss :0.248205\n",
      "epoch: 43 iterations: 400 loss :0.0537269\n",
      "epoch: 43 iterations: 500 loss :1.72749\n",
      "epoch: 43 iterations: 600 loss :0.0699069\n",
      "epoch: 43 iterations: 700 loss :0.0496526\n",
      "epoch: 43 iterations: 800 loss :0.00167028\n",
      "epoch: 43 iterations: 900 loss :0.752989\n",
      "epoch: 43 <====train track===> avg_loss: 0.00617284581809769, accuracy: 82.85714285714286% \n",
      "\n",
      "epoch 44 starting ...\n",
      "epoch: 44 iterations: 0 loss :0.312039\n",
      "epoch: 44 iterations: 100 loss :0.137308\n",
      "epoch: 44 iterations: 200 loss :0.00430182\n",
      "epoch: 44 iterations: 300 loss :0.998787\n",
      "epoch: 44 iterations: 400 loss :0.054056\n",
      "epoch: 44 iterations: 500 loss :0.00479595\n",
      "epoch: 44 iterations: 600 loss :0.0597572\n",
      "epoch: 44 iterations: 700 loss :0.0339019\n",
      "epoch: 44 iterations: 800 loss :0.125276\n",
      "epoch: 44 iterations: 900 loss :3.78852\n",
      "epoch: 44 <====train track===> avg_loss: 0.006353131128727385, accuracy: 83.80952380952381% \n",
      "\n",
      "epoch 45 starting ...\n",
      "epoch: 45 iterations: 0 loss :0.0683583\n",
      "epoch: 45 iterations: 100 loss :0.00314111\n",
      "epoch: 45 iterations: 200 loss :0.980084\n",
      "epoch: 45 iterations: 300 loss :0.150121\n",
      "epoch: 45 iterations: 400 loss :0.0100543\n",
      "epoch: 45 iterations: 500 loss :0.00190161\n",
      "epoch: 45 iterations: 600 loss :3.89167\n",
      "epoch: 45 iterations: 700 loss :0.230331\n",
      "epoch: 45 iterations: 800 loss :0.756823\n",
      "epoch: 45 iterations: 900 loss :0.864503\n",
      "epoch: 45 <====train track===> avg_loss: 0.006336326595136874, accuracy: 85.71428571428571% \n",
      "\n",
      "epoch 46 starting ...\n",
      "epoch: 46 iterations: 0 loss :0.372381\n",
      "epoch: 46 iterations: 100 loss :0.000307989\n",
      "epoch: 46 iterations: 200 loss :0.42538\n",
      "epoch: 46 iterations: 300 loss :0.417033\n",
      "epoch: 46 iterations: 400 loss :0.251765\n",
      "epoch: 46 iterations: 500 loss :0.00184283\n",
      "epoch: 46 iterations: 600 loss :0.0262125\n",
      "epoch: 46 iterations: 700 loss :0.00170217\n",
      "epoch: 46 iterations: 800 loss :0.00787357\n",
      "epoch: 46 iterations: 900 loss :0.698744\n",
      "epoch: 46 <====train track===> avg_loss: 0.00618960272511564, accuracy: 83.80952380952381% \n",
      "\n",
      "epoch 47 starting ...\n",
      "epoch: 47 iterations: 0 loss :0.1289\n",
      "epoch: 47 iterations: 100 loss :0.82071\n",
      "epoch: 47 iterations: 200 loss :0.00588423\n",
      "epoch: 47 iterations: 300 loss :0.31859\n",
      "epoch: 47 iterations: 400 loss :0.562151\n",
      "epoch: 47 iterations: 500 loss :0.095979\n",
      "epoch: 47 iterations: 600 loss :0.712704\n",
      "epoch: 47 iterations: 700 loss :0.00167587\n",
      "epoch: 47 iterations: 800 loss :0.00736664\n",
      "epoch: 47 iterations: 900 loss :0.32715\n",
      "epoch: 47 <====train track===> avg_loss: 0.005887666264787504, accuracy: 84.76190476190476% \n",
      "\n",
      "epoch 48 starting ...\n",
      "epoch: 48 iterations: 0 loss :0.0564316\n",
      "epoch: 48 iterations: 100 loss :1.53259\n",
      "epoch: 48 iterations: 200 loss :0.111726\n",
      "epoch: 48 iterations: 300 loss :2.87182\n",
      "epoch: 48 iterations: 400 loss :0.824636\n",
      "epoch: 48 iterations: 500 loss :5.64288\n",
      "epoch: 48 iterations: 600 loss :0.0475705\n",
      "epoch: 48 iterations: 700 loss :0.196091\n",
      "epoch: 48 iterations: 800 loss :0.116265\n",
      "epoch: 48 iterations: 900 loss :0.0253223\n",
      "epoch: 48 <====train track===> avg_loss: 0.006669213790749376, accuracy: 83.80952380952381% \n",
      "\n",
      "epoch 49 starting ...\n",
      "epoch: 49 iterations: 0 loss :0.013908\n",
      "epoch: 49 iterations: 100 loss :0.015214\n",
      "epoch: 49 iterations: 200 loss :0.0288134\n",
      "epoch: 49 iterations: 300 loss :0.00185187\n",
      "epoch: 49 iterations: 400 loss :0.000449676\n",
      "epoch: 49 iterations: 500 loss :0.851251\n",
      "epoch: 49 iterations: 600 loss :0.226508\n",
      "epoch: 49 iterations: 700 loss :1.49667\n",
      "epoch: 49 iterations: 800 loss :0.0103441\n",
      "epoch: 49 iterations: 900 loss :2.07778\n",
      "epoch: 49 <====train track===> avg_loss: 0.0062142445868270954, accuracy: 84.76190476190476% \n",
      "\n",
      "epoch 50 starting ...\n",
      "epoch: 50 iterations: 0 loss :2.42076\n",
      "epoch: 50 iterations: 100 loss :0.355373\n",
      "epoch: 50 iterations: 200 loss :1.18285\n",
      "epoch: 50 iterations: 300 loss :2.1562\n",
      "epoch: 50 iterations: 400 loss :0.0103738\n",
      "epoch: 50 iterations: 500 loss :0.195357\n",
      "epoch: 50 iterations: 600 loss :0.0080758\n",
      "epoch: 50 iterations: 700 loss :0.000471481\n",
      "epoch: 50 iterations: 800 loss :1.32258\n",
      "epoch: 50 iterations: 900 loss :0.064467\n",
      "epoch: 50 <====train track===> avg_loss: 0.006794858665257316, accuracy: 82.85714285714286% \n",
      "\n",
      "epoch 51 starting ...\n",
      "epoch: 51 iterations: 0 loss :0.0526084\n",
      "epoch: 51 iterations: 100 loss :0.0209375\n",
      "epoch: 51 iterations: 200 loss :0.43431\n",
      "epoch: 51 iterations: 300 loss :0.161873\n",
      "epoch: 51 iterations: 400 loss :0.872344\n",
      "epoch: 51 iterations: 500 loss :1.30125\n",
      "epoch: 51 iterations: 600 loss :1.04263\n",
      "epoch: 51 iterations: 700 loss :0.681956\n",
      "epoch: 51 iterations: 800 loss :0.468478\n",
      "epoch: 51 iterations: 900 loss :0.214044\n",
      "epoch: 51 <====train track===> avg_loss: 0.006109015501092649, accuracy: 82.85714285714286% \n",
      "\n",
      "epoch 52 starting ...\n",
      "epoch: 52 iterations: 0 loss :0.00202867\n",
      "epoch: 52 iterations: 100 loss :1.33453\n",
      "epoch: 52 iterations: 200 loss :1.02348\n",
      "epoch: 52 iterations: 300 loss :0.000310969\n",
      "epoch: 52 iterations: 400 loss :0.00338648\n",
      "epoch: 52 iterations: 500 loss :0.929256\n",
      "epoch: 52 iterations: 600 loss :2.59219\n",
      "epoch: 52 iterations: 700 loss :0.538803\n",
      "epoch: 52 iterations: 800 loss :0.0631365\n",
      "epoch: 52 iterations: 900 loss :0.625903\n",
      "epoch: 52 <====train track===> avg_loss: 0.006626863075340204, accuracy: 84.76190476190476% \n",
      "\n",
      "epoch 53 starting ...\n",
      "epoch: 53 iterations: 0 loss :0.00069046\n",
      "epoch: 53 iterations: 100 loss :0.164839\n",
      "epoch: 53 iterations: 200 loss :0.351489\n",
      "epoch: 53 iterations: 300 loss :0.00106516\n",
      "epoch: 53 iterations: 400 loss :0.598903\n",
      "epoch: 53 iterations: 500 loss :2.21684\n",
      "epoch: 53 iterations: 600 loss :0.353035\n",
      "epoch: 53 iterations: 700 loss :0.106241\n",
      "epoch: 53 iterations: 800 loss :0.651089\n",
      "epoch: 53 iterations: 900 loss :0.000324197\n",
      "epoch: 53 <====train track===> avg_loss: 0.0065531763158588364, accuracy: 79.04761904761905% \n",
      "\n",
      "epoch 54 starting ...\n",
      "epoch: 54 iterations: 0 loss :0.283997\n",
      "epoch: 54 iterations: 100 loss :0.0284354\n",
      "epoch: 54 iterations: 200 loss :0.013195\n",
      "epoch: 54 iterations: 300 loss :0.845964\n",
      "epoch: 54 iterations: 400 loss :0.0128951\n",
      "epoch: 54 iterations: 500 loss :0.264266\n",
      "epoch: 54 iterations: 600 loss :0.000407255\n",
      "epoch: 54 iterations: 700 loss :2.53741\n",
      "epoch: 54 iterations: 800 loss :0.413525\n",
      "epoch: 54 iterations: 900 loss :1.85311\n",
      "epoch: 54 <====train track===> avg_loss: 0.006047473752003976, accuracy: 84.76190476190476% \n",
      "\n",
      "epoch 55 starting ...\n",
      "epoch: 55 iterations: 0 loss :0.0934995\n",
      "epoch: 55 iterations: 100 loss :1.6221\n",
      "epoch: 55 iterations: 200 loss :0.488701\n",
      "epoch: 55 iterations: 300 loss :0.0580284\n",
      "epoch: 55 iterations: 400 loss :4.14458\n",
      "epoch: 55 iterations: 500 loss :0.0148564\n",
      "epoch: 55 iterations: 600 loss :0.00398271\n",
      "epoch: 55 iterations: 700 loss :0.0928007\n",
      "epoch: 55 iterations: 800 loss :0.0452903\n",
      "epoch: 55 iterations: 900 loss :0.0089409\n",
      "epoch: 55 <====train track===> avg_loss: 0.0057596736897628205, accuracy: 83.80952380952381% \n",
      "\n",
      "epoch 56 starting ...\n",
      "epoch: 56 iterations: 0 loss :0.000628512\n",
      "epoch: 56 iterations: 100 loss :0.0101958\n",
      "epoch: 56 iterations: 200 loss :0.0125687\n",
      "epoch: 56 iterations: 300 loss :0.000659606\n",
      "epoch: 56 iterations: 400 loss :0.0294034\n",
      "epoch: 56 iterations: 500 loss :0.000329679\n",
      "epoch: 56 iterations: 600 loss :4.1456\n",
      "epoch: 56 iterations: 700 loss :1.17798\n",
      "epoch: 56 iterations: 800 loss :0.0208622\n",
      "epoch: 56 iterations: 900 loss :0.294764\n",
      "epoch: 56 <====train track===> avg_loss: 0.006554266434152396, accuracy: 85.71428571428571% \n",
      "\n",
      "epoch 57 starting ...\n",
      "epoch: 57 iterations: 0 loss :2.17654\n",
      "epoch: 57 iterations: 100 loss :1.22196\n",
      "epoch: 57 iterations: 200 loss :0.0516559\n",
      "epoch: 57 iterations: 300 loss :0.255381\n",
      "epoch: 57 iterations: 400 loss :0.322597\n",
      "epoch: 57 iterations: 500 loss :0.932671\n",
      "epoch: 57 iterations: 600 loss :0.00240394\n",
      "epoch: 57 iterations: 700 loss :0.000720242\n",
      "epoch: 57 iterations: 800 loss :0.455202\n",
      "epoch: 57 iterations: 900 loss :0.153871\n",
      "epoch: 57 <====train track===> avg_loss: 0.006211418577206011, accuracy: 84.76190476190476% \n",
      "\n",
      "epoch 58 starting ...\n",
      "epoch: 58 iterations: 0 loss :0.00829678\n",
      "epoch: 58 iterations: 100 loss :0.553444\n",
      "epoch: 58 iterations: 200 loss :0.518646\n",
      "epoch: 58 iterations: 300 loss :0.000497098\n",
      "epoch: 58 iterations: 400 loss :1.14473\n",
      "epoch: 58 iterations: 500 loss :2.72721\n",
      "epoch: 58 iterations: 600 loss :0.0852662\n",
      "epoch: 58 iterations: 700 loss :0.113108\n",
      "epoch: 58 iterations: 800 loss :0.971597\n",
      "epoch: 58 iterations: 900 loss :1.26201\n",
      "epoch: 58 <====train track===> avg_loss: 0.006146766818814876, accuracy: 83.80952380952381% \n",
      "\n",
      "epoch 59 starting ...\n",
      "epoch: 59 iterations: 0 loss :0.962276\n",
      "epoch: 59 iterations: 100 loss :0.965185\n",
      "epoch: 59 iterations: 200 loss :3.88921\n",
      "epoch: 59 iterations: 300 loss :0.0450543\n",
      "epoch: 59 iterations: 400 loss :2.23922\n",
      "epoch: 59 iterations: 500 loss :2.19717\n",
      "epoch: 59 iterations: 600 loss :0.197505\n",
      "epoch: 59 iterations: 700 loss :0.032318\n",
      "epoch: 59 iterations: 800 loss :2.13179\n",
      "epoch: 59 iterations: 900 loss :0.850959\n",
      "epoch: 59 <====train track===> avg_loss: 0.006580269490781583, accuracy: 83.80952380952381% \n",
      "\n",
      "epoch 60 starting ...\n",
      "epoch: 60 iterations: 0 loss :1.28931\n",
      "epoch: 60 iterations: 100 loss :1.03335\n",
      "epoch: 60 iterations: 200 loss :1.97323\n",
      "epoch: 60 iterations: 300 loss :0.200234\n",
      "epoch: 60 iterations: 400 loss :0.817061\n",
      "epoch: 60 iterations: 500 loss :0.00460742\n",
      "epoch: 60 iterations: 600 loss :0.017665\n",
      "epoch: 60 iterations: 700 loss :0.000860916\n",
      "epoch: 60 iterations: 800 loss :0.00213693\n",
      "epoch: 60 iterations: 900 loss :0.0109083\n",
      "epoch: 60 <====train track===> avg_loss: 0.006327530389079927, accuracy: 84.76190476190476% \n",
      "\n",
      "epoch 61 starting ...\n",
      "epoch: 61 iterations: 0 loss :0.00175893\n",
      "epoch: 61 iterations: 100 loss :0.810976\n",
      "epoch: 61 iterations: 200 loss :1.95809\n",
      "epoch: 61 iterations: 300 loss :0.0945781\n",
      "epoch: 61 iterations: 400 loss :4.28163\n",
      "epoch: 61 iterations: 500 loss :0.000666277\n",
      "epoch: 61 iterations: 600 loss :7.22437\n",
      "epoch: 61 iterations: 700 loss :0.326485\n",
      "epoch: 61 iterations: 800 loss :0.981991\n",
      "epoch: 61 iterations: 900 loss :0.0287387\n",
      "epoch: 61 <====train track===> avg_loss: 0.0061053977882612595, accuracy: 85.71428571428571% \n",
      "\n",
      "epoch 62 starting ...\n",
      "epoch: 62 iterations: 0 loss :0.00394661\n",
      "epoch: 62 iterations: 100 loss :0.000445386\n",
      "epoch: 62 iterations: 200 loss :0.0308359\n",
      "epoch: 62 iterations: 300 loss :0.141185\n",
      "epoch: 62 iterations: 400 loss :0.112281\n",
      "epoch: 62 iterations: 500 loss :0.942404\n",
      "epoch: 62 iterations: 600 loss :0.0926629\n",
      "epoch: 62 iterations: 700 loss :0.0314717\n",
      "epoch: 62 iterations: 800 loss :0.793405\n",
      "epoch: 62 iterations: 900 loss :0.0539924\n",
      "epoch: 62 <====train track===> avg_loss: 0.006329226842981057, accuracy: 83.80952380952381% \n",
      "\n",
      "epoch 63 starting ...\n",
      "epoch: 63 iterations: 0 loss :1.19678\n",
      "epoch: 63 iterations: 100 loss :0.00271904\n",
      "epoch: 63 iterations: 200 loss :0.000636137\n",
      "epoch: 63 iterations: 300 loss :0.0638159\n",
      "epoch: 63 iterations: 400 loss :0.103174\n",
      "epoch: 63 iterations: 500 loss :0.0241092\n",
      "epoch: 63 iterations: 600 loss :0.606732\n",
      "epoch: 63 iterations: 700 loss :2.05642\n",
      "epoch: 63 iterations: 800 loss :0.0393426\n",
      "epoch: 63 iterations: 900 loss :0.624241\n",
      "epoch: 63 <====train track===> avg_loss: 0.006271180300435886, accuracy: 85.71428571428571% \n",
      "\n",
      "epoch 64 starting ...\n",
      "epoch: 64 iterations: 0 loss :0.611812\n",
      "epoch: 64 iterations: 100 loss :0.064188\n",
      "epoch: 64 iterations: 200 loss :0.435132\n",
      "epoch: 64 iterations: 300 loss :0.402813\n",
      "epoch: 64 iterations: 400 loss :0.517883\n",
      "epoch: 64 iterations: 500 loss :0.0251217\n",
      "epoch: 64 iterations: 600 loss :2.16905\n",
      "epoch: 64 iterations: 700 loss :0.254878\n",
      "epoch: 64 iterations: 800 loss :0.0266642\n",
      "epoch: 64 iterations: 900 loss :0.101208\n",
      "epoch: 64 <====train track===> avg_loss: 0.006518215619786243, accuracy: 84.76190476190476% \n",
      "\n",
      "epoch 65 starting ...\n",
      "epoch: 65 iterations: 0 loss :0.0947123\n",
      "epoch: 65 iterations: 100 loss :0.297938\n",
      "epoch: 65 iterations: 200 loss :0.0457467\n",
      "epoch: 65 iterations: 300 loss :0.20368\n",
      "epoch: 65 iterations: 400 loss :0.437709\n",
      "epoch: 65 iterations: 500 loss :0.126715\n",
      "epoch: 65 iterations: 600 loss :0.00269812\n",
      "epoch: 65 iterations: 700 loss :0.0408765\n",
      "epoch: 65 iterations: 800 loss :0.0621138\n",
      "epoch: 65 iterations: 900 loss :0.000851626\n",
      "epoch: 65 <====train track===> avg_loss: 0.006348792511491915, accuracy: 81.9047619047619% \n",
      "\n",
      "epoch 66 starting ...\n",
      "epoch: 66 iterations: 0 loss :0.186326\n",
      "epoch: 66 iterations: 100 loss :0.00196907\n",
      "epoch: 66 iterations: 200 loss :0.00265603\n",
      "epoch: 66 iterations: 300 loss :1.28171\n",
      "epoch: 66 iterations: 400 loss :0.00351336\n",
      "epoch: 66 iterations: 500 loss :1.02904\n",
      "epoch: 66 iterations: 600 loss :1.99762\n",
      "epoch: 66 iterations: 700 loss :0.0648916\n",
      "epoch: 66 iterations: 800 loss :0.0244695\n",
      "epoch: 66 iterations: 900 loss :0.0727089\n",
      "epoch: 66 <====train track===> avg_loss: 0.0063002588156162755, accuracy: 85.71428571428571% \n",
      "\n",
      "epoch 67 starting ...\n",
      "epoch: 67 iterations: 0 loss :1.68342\n",
      "epoch: 67 iterations: 100 loss :1.77167\n",
      "epoch: 67 iterations: 200 loss :0.0519355\n",
      "epoch: 67 iterations: 300 loss :0.836509\n",
      "epoch: 67 iterations: 400 loss :0.81555\n",
      "epoch: 67 iterations: 500 loss :0.549423\n",
      "epoch: 67 iterations: 600 loss :0.135549\n",
      "epoch: 67 iterations: 700 loss :0.407811\n",
      "epoch: 67 iterations: 800 loss :1.75718\n",
      "epoch: 67 iterations: 900 loss :2.61258\n",
      "epoch: 67 <====train track===> avg_loss: 0.006375713592958137, accuracy: 85.71428571428571% \n",
      "\n",
      "epoch 68 starting ...\n",
      "epoch: 68 iterations: 0 loss :0.0121722\n",
      "epoch: 68 iterations: 100 loss :0.273121\n",
      "epoch: 68 iterations: 200 loss :0.0164134\n",
      "epoch: 68 iterations: 300 loss :0.262019\n",
      "epoch: 68 iterations: 400 loss :1.22471\n",
      "epoch: 68 iterations: 500 loss :0.00400776\n",
      "epoch: 68 iterations: 600 loss :0.418639\n",
      "epoch: 68 iterations: 700 loss :0.16227\n",
      "epoch: 68 iterations: 800 loss :1.44431\n",
      "epoch: 68 iterations: 900 loss :0.871729\n",
      "epoch: 68 <====train track===> avg_loss: 0.005705714298826494, accuracy: 85.71428571428571% \n",
      "\n",
      "epoch 69 starting ...\n",
      "epoch: 69 iterations: 0 loss :0.0211416\n",
      "epoch: 69 iterations: 100 loss :0.838923\n",
      "epoch: 69 iterations: 200 loss :0.278068\n",
      "epoch: 69 iterations: 300 loss :1.43053\n",
      "epoch: 69 iterations: 400 loss :0.142383\n",
      "epoch: 69 iterations: 500 loss :0.632447\n",
      "epoch: 69 iterations: 600 loss :0.0274333\n",
      "epoch: 69 iterations: 700 loss :0.0226587\n",
      "epoch: 69 iterations: 800 loss :0.269575\n",
      "epoch: 69 iterations: 900 loss :0.000673901\n",
      "epoch: 69 <====train track===> avg_loss: 0.005815997207445443, accuracy: 84.76190476190476% \n",
      "\n",
      "epoch 70 starting ...\n",
      "epoch: 70 iterations: 0 loss :0.0169344\n",
      "epoch: 70 iterations: 100 loss :0.372004\n",
      "epoch: 70 iterations: 200 loss :0.00433719\n",
      "epoch: 70 iterations: 300 loss :0.0600152\n",
      "epoch: 70 iterations: 400 loss :0.0809325\n",
      "epoch: 70 iterations: 500 loss :0.75689\n",
      "epoch: 70 iterations: 600 loss :0.242143\n",
      "epoch: 70 iterations: 700 loss :0.00635543\n",
      "epoch: 70 iterations: 800 loss :0.0188578\n",
      "epoch: 70 iterations: 900 loss :0.504457\n",
      "epoch: 70 <====train track===> avg_loss: 0.006594125926134794, accuracy: 81.9047619047619% \n",
      "\n",
      "epoch 71 starting ...\n",
      "epoch: 71 iterations: 0 loss :0.338307\n",
      "epoch: 71 iterations: 100 loss :0.000741922\n",
      "epoch: 71 iterations: 200 loss :0.13676\n",
      "epoch: 71 iterations: 300 loss :0.0344328\n",
      "epoch: 71 iterations: 400 loss :0.030635\n",
      "epoch: 71 iterations: 500 loss :0.34768\n",
      "epoch: 71 iterations: 600 loss :0.00109767\n",
      "epoch: 71 iterations: 700 loss :0.242007\n",
      "epoch: 71 iterations: 800 loss :0.958332\n",
      "epoch: 71 iterations: 900 loss :0.212044\n",
      "epoch: 71 <====train track===> avg_loss: 0.006263345643028523, accuracy: 84.76190476190476% \n",
      "\n",
      "epoch 72 starting ...\n",
      "epoch: 72 iterations: 0 loss :0.000821491\n",
      "epoch: 72 iterations: 100 loss :1.0916\n",
      "epoch: 72 iterations: 200 loss :0.00117019\n",
      "epoch: 72 iterations: 300 loss :4.38507\n",
      "epoch: 72 iterations: 400 loss :0.116216\n",
      "epoch: 72 iterations: 500 loss :0.155096\n",
      "epoch: 72 iterations: 600 loss :0.146904\n",
      "epoch: 72 iterations: 700 loss :0.277885\n",
      "epoch: 72 iterations: 800 loss :0.0690975\n",
      "epoch: 72 iterations: 900 loss :0.142629\n",
      "epoch: 72 <====train track===> avg_loss: 0.006307584409565368, accuracy: 83.80952380952381% \n",
      "\n",
      "epoch 73 starting ...\n",
      "epoch: 73 iterations: 0 loss :0.341382\n",
      "epoch: 73 iterations: 100 loss :0.630798\n",
      "epoch: 73 iterations: 200 loss :2.14394\n",
      "epoch: 73 iterations: 300 loss :0.0610669\n",
      "epoch: 73 iterations: 400 loss :0.620116\n",
      "epoch: 73 iterations: 500 loss :7.27723\n",
      "epoch: 73 iterations: 600 loss :0.0572224\n",
      "epoch: 73 iterations: 700 loss :0.000747878\n",
      "epoch: 73 iterations: 800 loss :0.000506869\n",
      "epoch: 73 iterations: 900 loss :1.7223\n",
      "epoch: 73 <====train track===> avg_loss: 0.006377889278891171, accuracy: 83.80952380952381% \n",
      "\n",
      "epoch 74 starting ...\n",
      "epoch: 74 iterations: 0 loss :0.507508\n",
      "epoch: 74 iterations: 100 loss :0.153551\n",
      "epoch: 74 iterations: 200 loss :0.0589841\n",
      "epoch: 74 iterations: 300 loss :0.0285555\n",
      "epoch: 74 iterations: 400 loss :0.0130949\n",
      "epoch: 74 iterations: 500 loss :0.111182\n",
      "epoch: 74 iterations: 600 loss :0.779969\n",
      "epoch: 74 iterations: 700 loss :0.00148829\n",
      "epoch: 74 iterations: 800 loss :0.552091\n",
      "epoch: 74 iterations: 900 loss :1.36156\n",
      "epoch: 74 <====train track===> avg_loss: 0.005746968920799004, accuracy: 84.76190476190476% \n",
      "\n",
      "epoch 75 starting ...\n",
      "epoch: 75 iterations: 0 loss :0.254788\n",
      "epoch: 75 iterations: 100 loss :0.00414809\n",
      "epoch: 75 iterations: 200 loss :0.256214\n",
      "epoch: 75 iterations: 300 loss :0.506539\n",
      "epoch: 75 iterations: 400 loss :0.0525232\n",
      "epoch: 75 iterations: 500 loss :0.0283523\n",
      "epoch: 75 iterations: 600 loss :0.0223705\n",
      "epoch: 75 iterations: 700 loss :0.331602\n",
      "epoch: 75 iterations: 800 loss :0.273194\n",
      "epoch: 75 iterations: 900 loss :0.0121149\n",
      "epoch: 75 <====train track===> avg_loss: 0.006426275623969562, accuracy: 85.71428571428571% \n",
      "\n",
      "epoch 76 starting ...\n",
      "epoch: 76 iterations: 0 loss :0.133442\n",
      "epoch: 76 iterations: 100 loss :0.144307\n",
      "epoch: 76 iterations: 200 loss :0.0613737\n",
      "epoch: 76 iterations: 300 loss :0.0453019\n",
      "epoch: 76 iterations: 400 loss :0.00624443\n",
      "epoch: 76 iterations: 500 loss :0.558635\n",
      "epoch: 76 iterations: 600 loss :1.06676\n",
      "epoch: 76 iterations: 700 loss :0.0549094\n",
      "epoch: 76 iterations: 800 loss :0.0435126\n",
      "epoch: 76 iterations: 900 loss :0.460744\n",
      "epoch: 76 <====train track===> avg_loss: 0.005671332922691847, accuracy: 86.66666666666667% \n",
      "\n",
      "epoch 77 starting ...\n",
      "epoch: 77 iterations: 0 loss :0.00662855\n",
      "epoch: 77 iterations: 100 loss :5.19274\n",
      "epoch: 77 iterations: 200 loss :0.0272926\n",
      "epoch: 77 iterations: 300 loss :0.000947861\n",
      "epoch: 77 iterations: 400 loss :0.124025\n",
      "epoch: 77 iterations: 500 loss :0.115814\n",
      "epoch: 77 iterations: 600 loss :0.000405706\n",
      "epoch: 77 iterations: 700 loss :0.0313333\n",
      "epoch: 77 iterations: 800 loss :0.00817607\n",
      "epoch: 77 iterations: 900 loss :0.639894\n",
      "epoch: 77 <====train track===> avg_loss: 0.005834111310385339, accuracy: 85.71428571428571% \n",
      "\n",
      "epoch 78 starting ...\n",
      "epoch: 78 iterations: 0 loss :1.64882\n",
      "epoch: 78 iterations: 100 loss :1.13649\n",
      "epoch: 78 iterations: 200 loss :0.434384\n",
      "epoch: 78 iterations: 300 loss :0.00515038\n",
      "epoch: 78 iterations: 400 loss :0.631076\n",
      "epoch: 78 iterations: 500 loss :0.150654\n",
      "epoch: 78 iterations: 600 loss :0.085805\n",
      "epoch: 78 iterations: 700 loss :0.734484\n",
      "epoch: 78 iterations: 800 loss :0.302805\n",
      "epoch: 78 iterations: 900 loss :0.0612721\n",
      "epoch: 78 <====train track===> avg_loss: 0.006118837088122998, accuracy: 83.80952380952381% \n",
      "\n",
      "epoch 79 starting ...\n",
      "epoch: 79 iterations: 0 loss :0.00113506\n",
      "epoch: 79 iterations: 100 loss :0.0176516\n",
      "epoch: 79 iterations: 200 loss :1.78479\n",
      "epoch: 79 iterations: 300 loss :0.00236125\n",
      "epoch: 79 iterations: 400 loss :0.730759\n",
      "epoch: 79 iterations: 500 loss :0.00604444\n",
      "epoch: 79 iterations: 600 loss :0.00722226\n",
      "epoch: 79 iterations: 700 loss :0.0482098\n",
      "epoch: 79 iterations: 800 loss :5.08763\n",
      "epoch: 79 iterations: 900 loss :0.0295414\n",
      "epoch: 79 <====train track===> avg_loss: 0.006400189686220925, accuracy: 86.66666666666667% \n",
      "\n",
      "epoch 80 starting ...\n",
      "epoch: 80 iterations: 0 loss :1.42509\n",
      "epoch: 80 iterations: 100 loss :0.775041\n",
      "epoch: 80 iterations: 200 loss :1.25236\n",
      "epoch: 80 iterations: 300 loss :0.468758\n",
      "epoch: 80 iterations: 400 loss :0.00206044\n",
      "epoch: 80 iterations: 500 loss :0.00223446\n",
      "epoch: 80 iterations: 600 loss :2.47929\n",
      "epoch: 80 iterations: 700 loss :0.743088\n",
      "epoch: 80 iterations: 800 loss :4.51153\n",
      "epoch: 80 iterations: 900 loss :0.00394103\n",
      "epoch: 80 <====train track===> avg_loss: 0.005908308112555508, accuracy: 80.95238095238095% \n",
      "\n",
      "epoch 81 starting ...\n",
      "epoch: 81 iterations: 0 loss :0.115711\n",
      "epoch: 81 iterations: 100 loss :0.172266\n",
      "epoch: 81 iterations: 200 loss :0.991116\n",
      "epoch: 81 iterations: 300 loss :1.15339\n",
      "epoch: 81 iterations: 400 loss :0.5986\n",
      "epoch: 81 iterations: 500 loss :0.729714\n",
      "epoch: 81 iterations: 600 loss :0.179904\n",
      "epoch: 81 iterations: 700 loss :0.45605\n",
      "epoch: 81 iterations: 800 loss :1.53178\n",
      "epoch: 81 iterations: 900 loss :1.69895\n",
      "epoch: 81 <====train track===> avg_loss: 0.005992570508228488, accuracy: 83.80952380952381% \n",
      "\n",
      "epoch 82 starting ...\n",
      "epoch: 82 iterations: 0 loss :0.00121805\n",
      "epoch: 82 iterations: 100 loss :4.94128\n",
      "epoch: 82 iterations: 200 loss :0.16563\n",
      "epoch: 82 iterations: 300 loss :0.0857251\n",
      "epoch: 82 iterations: 400 loss :0.540378\n",
      "epoch: 82 iterations: 500 loss :0.000579666\n",
      "epoch: 82 iterations: 600 loss :0.196711\n",
      "epoch: 82 iterations: 700 loss :0.60092\n",
      "epoch: 82 iterations: 800 loss :0.00524929\n",
      "epoch: 82 iterations: 900 loss :0.569033\n",
      "epoch: 82 <====train track===> avg_loss: 0.006573115930730575, accuracy: 86.66666666666667% \n",
      "\n",
      "epoch 83 starting ...\n",
      "epoch: 83 iterations: 0 loss :0.0518643\n",
      "epoch: 83 iterations: 100 loss :0.124681\n",
      "epoch: 83 iterations: 200 loss :0.000986328\n",
      "epoch: 83 iterations: 300 loss :0.0788201\n",
      "epoch: 83 iterations: 400 loss :1.01323\n",
      "epoch: 83 iterations: 500 loss :0.130901\n",
      "epoch: 83 iterations: 600 loss :0.0017011\n",
      "epoch: 83 iterations: 700 loss :0.451471\n",
      "epoch: 83 iterations: 800 loss :0.886823\n",
      "epoch: 83 iterations: 900 loss :0.200467\n",
      "epoch: 83 <====train track===> avg_loss: 0.006084172844183072, accuracy: 85.71428571428571% \n",
      "\n",
      "epoch 84 starting ...\n",
      "epoch: 84 iterations: 0 loss :0.492618\n",
      "epoch: 84 iterations: 100 loss :0.272369\n",
      "epoch: 84 iterations: 200 loss :1.67198\n",
      "epoch: 84 iterations: 300 loss :1.1206\n",
      "epoch: 84 iterations: 400 loss :0.727263\n",
      "epoch: 84 iterations: 500 loss :0.209776\n",
      "epoch: 84 iterations: 600 loss :0.130262\n",
      "epoch: 84 iterations: 700 loss :0.155126\n",
      "epoch: 84 iterations: 800 loss :0.0302939\n",
      "epoch: 84 iterations: 900 loss :1.4583\n",
      "epoch: 84 <====train track===> avg_loss: 0.0062656506354228265, accuracy: 88.57142857142857% \n",
      "\n",
      "epoch 85 starting ...\n",
      "epoch: 85 iterations: 0 loss :0.70289\n",
      "epoch: 85 iterations: 100 loss :0.429694\n",
      "epoch: 85 iterations: 200 loss :0.000952148\n",
      "epoch: 85 iterations: 300 loss :0.0510096\n",
      "epoch: 85 iterations: 400 loss :0.601382\n",
      "epoch: 85 iterations: 500 loss :0.0503053\n",
      "epoch: 85 iterations: 600 loss :0.285775\n",
      "epoch: 85 iterations: 700 loss :0.195035\n",
      "epoch: 85 iterations: 800 loss :0.0948682\n",
      "epoch: 85 iterations: 900 loss :0.246986\n",
      "epoch: 85 <====train track===> avg_loss: 0.006154225487563973, accuracy: 86.66666666666667% \n",
      "\n",
      "epoch 86 starting ...\n",
      "epoch: 86 iterations: 0 loss :0.233949\n",
      "epoch: 86 iterations: 100 loss :0.00457229\n",
      "epoch: 86 iterations: 200 loss :1.11282\n",
      "epoch: 86 iterations: 300 loss :0.293397\n",
      "epoch: 86 iterations: 400 loss :0.00513188\n",
      "epoch: 86 iterations: 500 loss :0.00449433\n",
      "epoch: 86 iterations: 600 loss :0.0290091\n",
      "epoch: 86 iterations: 700 loss :0.0229683\n",
      "epoch: 86 iterations: 800 loss :0.00131568\n",
      "epoch: 86 iterations: 900 loss :0.749758\n",
      "epoch: 86 <====train track===> avg_loss: 0.005999182501648957, accuracy: 83.80952380952381% \n",
      "\n",
      "epoch 87 starting ...\n",
      "epoch: 87 iterations: 0 loss :1.92128\n",
      "epoch: 87 iterations: 100 loss :0.319685\n",
      "epoch: 87 iterations: 200 loss :0.0149735\n",
      "epoch: 87 iterations: 300 loss :0.230216\n",
      "epoch: 87 iterations: 400 loss :0.941134\n",
      "epoch: 87 iterations: 500 loss :1.65132\n",
      "epoch: 87 iterations: 600 loss :0.366937\n",
      "epoch: 87 iterations: 700 loss :0.148533\n",
      "epoch: 87 iterations: 800 loss :0.893295\n",
      "epoch: 87 iterations: 900 loss :2.7866\n",
      "epoch: 87 <====train track===> avg_loss: 0.005886367914123753, accuracy: 85.71428571428571% \n",
      "\n",
      "epoch 88 starting ...\n",
      "epoch: 88 iterations: 0 loss :0.275847\n",
      "epoch: 88 iterations: 100 loss :0.0102032\n",
      "epoch: 88 iterations: 200 loss :1.52687\n",
      "epoch: 88 iterations: 300 loss :0.586419\n",
      "epoch: 88 iterations: 400 loss :0.317486\n",
      "epoch: 88 iterations: 500 loss :0.23584\n",
      "epoch: 88 iterations: 600 loss :0.26702\n",
      "epoch: 88 iterations: 700 loss :0.0115486\n",
      "epoch: 88 iterations: 800 loss :4.12661\n",
      "epoch: 88 iterations: 900 loss :0.0277799\n",
      "epoch: 88 <====train track===> avg_loss: 0.0054947191521109925, accuracy: 82.85714285714286% \n",
      "\n",
      "epoch 89 starting ...\n",
      "epoch: 89 iterations: 0 loss :0.0215832\n",
      "epoch: 89 iterations: 100 loss :1.91816\n",
      "epoch: 89 iterations: 200 loss :0.00384615\n",
      "epoch: 89 iterations: 300 loss :0.0184022\n",
      "epoch: 89 iterations: 400 loss :0.000559293\n",
      "epoch: 89 iterations: 500 loss :0.245008\n",
      "epoch: 89 iterations: 600 loss :0.546077\n",
      "epoch: 89 iterations: 700 loss :0.269557\n",
      "epoch: 89 iterations: 800 loss :2.06761\n",
      "epoch: 89 iterations: 900 loss :0.980878\n",
      "epoch: 89 <====train track===> avg_loss: 0.0060665796541695734, accuracy: 85.71428571428571% \n",
      "\n",
      "epoch 90 starting ...\n",
      "epoch: 90 iterations: 0 loss :0.988688\n",
      "epoch: 90 iterations: 100 loss :0.766575\n",
      "epoch: 90 iterations: 200 loss :0.0500162\n",
      "epoch: 90 iterations: 300 loss :0.709998\n",
      "epoch: 90 iterations: 400 loss :0.226282\n",
      "epoch: 90 iterations: 500 loss :0.00296344\n",
      "epoch: 90 iterations: 600 loss :0.475712\n",
      "epoch: 90 iterations: 700 loss :0.718654\n",
      "epoch: 90 iterations: 800 loss :0.195525\n",
      "epoch: 90 iterations: 900 loss :0.000344456\n",
      "epoch: 90 <====train track===> avg_loss: 0.006124277831847785, accuracy: 81.9047619047619% \n",
      "\n",
      "epoch 91 starting ...\n",
      "epoch: 91 iterations: 0 loss :0.177023\n",
      "epoch: 91 iterations: 100 loss :0.116012\n",
      "epoch: 91 iterations: 200 loss :0.475514\n",
      "epoch: 91 iterations: 300 loss :0.0749624\n",
      "epoch: 91 iterations: 400 loss :0.00275554\n",
      "epoch: 91 iterations: 500 loss :0.00271785\n",
      "epoch: 91 iterations: 600 loss :0.150474\n",
      "epoch: 91 iterations: 700 loss :0.548667\n",
      "epoch: 91 iterations: 800 loss :0.190251\n",
      "epoch: 91 iterations: 900 loss :0.000742636\n",
      "epoch: 91 <====train track===> avg_loss: 0.006047716701748284, accuracy: 82.85714285714286% \n",
      "\n",
      "epoch 92 starting ...\n",
      "epoch: 92 iterations: 0 loss :0.663832\n",
      "epoch: 92 iterations: 100 loss :0.147051\n",
      "epoch: 92 iterations: 200 loss :0.0863637\n",
      "epoch: 92 iterations: 300 loss :0.133817\n",
      "epoch: 92 iterations: 400 loss :0.908152\n",
      "epoch: 92 iterations: 500 loss :0.0437518\n",
      "epoch: 92 iterations: 600 loss :0.00452388\n",
      "epoch: 92 iterations: 700 loss :0.0121201\n",
      "epoch: 92 iterations: 800 loss :0.072919\n",
      "epoch: 92 iterations: 900 loss :0.00118067\n",
      "epoch: 92 <====train track===> avg_loss: 0.005784774942294003, accuracy: 84.76190476190476% \n",
      "\n",
      "epoch 93 starting ...\n",
      "epoch: 93 iterations: 0 loss :0.249094\n",
      "epoch: 93 iterations: 100 loss :0.0194663\n",
      "epoch: 93 iterations: 200 loss :0.383597\n",
      "epoch: 93 iterations: 300 loss :0.200849\n",
      "epoch: 93 iterations: 400 loss :0.156682\n",
      "epoch: 93 iterations: 500 loss :0.268116\n",
      "epoch: 93 iterations: 600 loss :0.377809\n",
      "epoch: 93 iterations: 700 loss :0.0635387\n",
      "epoch: 93 iterations: 800 loss :0.0045329\n",
      "epoch: 93 iterations: 900 loss :1.0091\n",
      "epoch: 93 <====train track===> avg_loss: 0.006263502888087007, accuracy: 83.80952380952381% \n",
      "\n",
      "epoch 94 starting ...\n",
      "epoch: 94 iterations: 0 loss :0.0593613\n",
      "epoch: 94 iterations: 100 loss :0.0035952\n",
      "epoch: 94 iterations: 200 loss :0.437601\n",
      "epoch: 94 iterations: 300 loss :0.00116471\n",
      "epoch: 94 iterations: 400 loss :0.160808\n",
      "epoch: 94 iterations: 500 loss :0.00287845\n",
      "epoch: 94 iterations: 600 loss :0.00287037\n",
      "epoch: 94 iterations: 700 loss :1.11646\n",
      "epoch: 94 iterations: 800 loss :0.0549941\n",
      "epoch: 94 iterations: 900 loss :0.280788\n",
      "epoch: 94 <====train track===> avg_loss: 0.0059355342895222474, accuracy: 85.71428571428571% \n",
      "\n",
      "epoch 95 starting ...\n",
      "epoch: 95 iterations: 0 loss :0.539694\n",
      "epoch: 95 iterations: 100 loss :0.131554\n",
      "epoch: 95 iterations: 200 loss :0.018368\n",
      "epoch: 95 iterations: 300 loss :0.00356764\n",
      "epoch: 95 iterations: 400 loss :0.53954\n",
      "epoch: 95 iterations: 500 loss :1.54928\n",
      "epoch: 95 iterations: 600 loss :0.0927522\n",
      "epoch: 95 iterations: 700 loss :0.224924\n",
      "epoch: 95 iterations: 800 loss :1.07447\n",
      "epoch: 95 iterations: 900 loss :0.297975\n",
      "epoch: 95 <====train track===> avg_loss: 0.006388284232210055, accuracy: 87.61904761904762% \n",
      "\n",
      "epoch 96 starting ...\n",
      "epoch: 96 iterations: 0 loss :0.108517\n",
      "epoch: 96 iterations: 100 loss :0.00109827\n",
      "epoch: 96 iterations: 200 loss :0.00281177\n",
      "epoch: 96 iterations: 300 loss :0.52079\n",
      "epoch: 96 iterations: 400 loss :0.0595394\n",
      "epoch: 96 iterations: 500 loss :0.738893\n",
      "epoch: 96 iterations: 600 loss :0.442868\n",
      "epoch: 96 iterations: 700 loss :0.00295762\n",
      "epoch: 96 iterations: 800 loss :0.0115634\n",
      "epoch: 96 iterations: 900 loss :1.9062\n",
      "epoch: 96 <====train track===> avg_loss: 0.005561289954679669, accuracy: 85.71428571428571% \n",
      "\n",
      "epoch 97 starting ...\n",
      "epoch: 97 iterations: 0 loss :0.218813\n",
      "epoch: 97 iterations: 100 loss :1.11636\n",
      "epoch: 97 iterations: 200 loss :0.0110571\n",
      "epoch: 97 iterations: 300 loss :0.123253\n",
      "epoch: 97 iterations: 400 loss :0.0236876\n",
      "epoch: 97 iterations: 500 loss :0.00153019\n",
      "epoch: 97 iterations: 600 loss :0.0720332\n",
      "epoch: 97 iterations: 700 loss :0.407827\n",
      "epoch: 97 iterations: 800 loss :0.151107\n",
      "epoch: 97 iterations: 900 loss :0.0376164\n",
      "epoch: 97 <====train track===> avg_loss: 0.0057196121623255824, accuracy: 86.66666666666667% \n",
      "\n",
      "epoch 98 starting ...\n",
      "epoch: 98 iterations: 0 loss :2.45745\n",
      "epoch: 98 iterations: 100 loss :0.156783\n",
      "epoch: 98 iterations: 200 loss :0.00499264\n",
      "epoch: 98 iterations: 300 loss :0.00559846\n",
      "epoch: 98 iterations: 400 loss :0.608562\n",
      "epoch: 98 iterations: 500 loss :0.00277468\n",
      "epoch: 98 iterations: 600 loss :0.0523677\n",
      "epoch: 98 iterations: 700 loss :0.706786\n",
      "epoch: 98 iterations: 800 loss :0.56463\n",
      "epoch: 98 iterations: 900 loss :0.00722581\n",
      "epoch: 98 <====train track===> avg_loss: 0.006059768568141842, accuracy: 84.76190476190476% \n",
      "\n",
      "epoch 99 starting ...\n",
      "epoch: 99 iterations: 0 loss :0.334733\n",
      "epoch: 99 iterations: 100 loss :0.0600764\n",
      "epoch: 99 iterations: 200 loss :0.417422\n",
      "epoch: 99 iterations: 300 loss :0.193525\n",
      "epoch: 99 iterations: 400 loss :0.433928\n",
      "epoch: 99 iterations: 500 loss :0.0469609\n",
      "epoch: 99 iterations: 600 loss :0.0192739\n",
      "epoch: 99 iterations: 700 loss :2.1789\n",
      "epoch: 99 iterations: 800 loss :0.0513495\n",
      "epoch: 99 iterations: 900 loss :1.23716\n",
      "epoch: 99 <====train track===> avg_loss: 0.0060548542628768185, accuracy: 86.66666666666667% \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'avg loss')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9e6c199f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9e14148390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#training function\n",
    "def train(model, num_epoch, num_iter, rec_interval, disp_interval):\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 1e-6)\n",
    "    loss_values = []\n",
    "    avg_loss_values = []\n",
    "    rec_step = 0\n",
    "    print('Starting the training ...')\n",
    "    for eph in range(num_epoch):\n",
    "        print('epoch {} starting ...'.format(eph))\n",
    "        avg_loss = 0\n",
    "        n_samples = 0\n",
    "        for i in range(num_iter):\n",
    "            model.hidden3 = (model.hidden3[0].detach(), model.hidden3[1].detach())\n",
    "            model.hidden2_1 = (model.hidden2_1[0].detach(), model.hidden2_1[1].detach())\n",
    "            model.hidden2_2 = (model.hidden2_2[0].detach(), model.hidden2_2[1].detach())\n",
    "            model.hidden2_3 = (model.hidden2_3[0].detach(), model.hidden2_3[1].detach())\n",
    "            model.zero_grad()\n",
    "            X,Y = next(ACTd)\n",
    "            n_samples += len(X)\n",
    "            X = autograd.Variable(torch.from_numpy(X).float().cuda())\n",
    "            X = X.view(len(X), 1, -1)\n",
    "            Y = autograd.Variable(torch.LongTensor(np.array([Y])).cuda())\n",
    "\n",
    "            y_hat = model(X)\n",
    "#             print(eph, i, y_hat)\n",
    "            loss = F.cross_entropy(y_hat, Y)\n",
    "            avg_loss += loss.data[0]\n",
    "            \n",
    "            if i % disp_interval == 0:\n",
    "                print('epoch: %d iterations: %d loss :%g' % (eph, i, loss.data[0]))\n",
    "            if rec_step%rec_interval==0:\n",
    "                loss_values.append(loss.data[0])\n",
    "            \n",
    "            loss.backward()     \n",
    "            optimizer.step()\n",
    "            rec_step += 1\n",
    "            \n",
    "        avg_loss /= n_samples\n",
    "        avg_loss_values.append(avg_loss)\n",
    "        #evaluating model accuracy\n",
    "        acc = evaluate_accuracy(model, test_split)\n",
    "        print('epoch: {} <====train track===> avg_loss: {}, accuracy: {}% \\n'.format(eph, avg_loss, acc))\n",
    "    return loss_values, avg_loss_values\n",
    "\n",
    "\n",
    "loss_vals, avg_loss_vals = train(model0, 100, 1000, 2, 100) #100eph_8e-6, \n",
    "plt.figure()\n",
    "plt.plot(loss_vals)\n",
    "plt.figure()\n",
    "plt.plot(avg_loss_vals)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('avg loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_loss_v1 = avg_loss_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_loss_v1 += avg_loss_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'avg loss')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9e12fc8dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_loss_v1)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('avg loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model\n",
    "def save_model(model_name, path, model):\n",
    "    p = path+'/'+model_name\n",
    "    print('saving at {}'.format(p))\n",
    "    torch.save(model.state_dict(), p)\n",
    "    print('saved at {}'.format(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving at ./checkpoints/LSTMClassifierX3_c7.pth\n",
      "saved at ./checkpoints/LSTMClassifierX3_c7.pth\n"
     ]
    }
   ],
   "source": [
    "save_model('LSTMClassifierX3_c7.pth', './checkpoints', model0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtest = LSTMClassifier(75, 512, 7, 1, 2, 3).cuda()\n",
    "mtest.load_state_dict(torch.load('./checkpoints/LSTMClassifierX3_c7.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       " 3.9143e-02  2.4818e-02  3.2468e-02  ...   8.5511e-03 -1.7184e-02 -3.2849e-02\n",
       "-1.3644e-02 -4.0704e-02  3.7073e-02  ...  -3.0386e-02 -2.2615e-02 -4.2696e-02\n",
       "-2.8556e-02 -3.3357e-03  3.7336e-02  ...   5.2892e-03 -1.9198e-02  3.0822e-02\n",
       "                ...                   â‹±                   ...                \n",
       "-2.1083e-02  3.5893e-02 -1.1259e-03  ...   2.0177e-02  3.5760e-02  3.1273e-02\n",
       " 5.1477e-03 -2.0578e-02  4.1886e-02  ...  -1.3133e-02  2.3866e-02 -2.6527e-02\n",
       "-2.6014e-04  9.1317e-03  2.4725e-03  ...   2.3441e-02  1.9406e-02  1.0368e-02\n",
       "[torch.cuda.FloatTensor of size 2048x512 (GPU 0)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtest.lstm3.weight_hh_l0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
