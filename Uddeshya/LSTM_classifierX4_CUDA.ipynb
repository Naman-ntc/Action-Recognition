{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f49d00318b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import random, numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the datasets, i.e loading frames for few actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.382997</td>\n",
       "      <td>-0.419442</td>\n",
       "      <td>3.449989</td>\n",
       "      <td>-0.366909</td>\n",
       "      <td>-0.092619</td>\n",
       "      <td>3.443680</td>\n",
       "      <td>-0.353380</td>\n",
       "      <td>0.229542</td>\n",
       "      <td>3.427116</td>\n",
       "      <td>-0.391862</td>\n",
       "      <td>...</td>\n",
       "      <td>3.636719</td>\n",
       "      <td>-0.435790</td>\n",
       "      <td>-0.536338</td>\n",
       "      <td>3.280097</td>\n",
       "      <td>-0.364369</td>\n",
       "      <td>-0.491436</td>\n",
       "      <td>3.269750</td>\n",
       "      <td>1</td>\n",
       "      <td>72057594037944340</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.383146</td>\n",
       "      <td>-0.419292</td>\n",
       "      <td>3.450006</td>\n",
       "      <td>-0.367569</td>\n",
       "      <td>-0.092003</td>\n",
       "      <td>3.443895</td>\n",
       "      <td>-0.353885</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>3.427162</td>\n",
       "      <td>-0.391820</td>\n",
       "      <td>...</td>\n",
       "      <td>3.633053</td>\n",
       "      <td>-0.436031</td>\n",
       "      <td>-0.536649</td>\n",
       "      <td>3.281972</td>\n",
       "      <td>-0.358806</td>\n",
       "      <td>-0.471054</td>\n",
       "      <td>3.269975</td>\n",
       "      <td>1</td>\n",
       "      <td>72057594037944340</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.385776</td>\n",
       "      <td>-0.421191</td>\n",
       "      <td>3.449611</td>\n",
       "      <td>-0.369506</td>\n",
       "      <td>-0.092775</td>\n",
       "      <td>3.443796</td>\n",
       "      <td>-0.354571</td>\n",
       "      <td>0.230189</td>\n",
       "      <td>3.426965</td>\n",
       "      <td>-0.403822</td>\n",
       "      <td>...</td>\n",
       "      <td>3.632370</td>\n",
       "      <td>-0.436489</td>\n",
       "      <td>-0.536484</td>\n",
       "      <td>3.286322</td>\n",
       "      <td>-0.358079</td>\n",
       "      <td>-0.470344</td>\n",
       "      <td>3.270202</td>\n",
       "      <td>1</td>\n",
       "      <td>72057594037944340</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.385807</td>\n",
       "      <td>-0.421205</td>\n",
       "      <td>3.449582</td>\n",
       "      <td>-0.369576</td>\n",
       "      <td>-0.092714</td>\n",
       "      <td>3.443878</td>\n",
       "      <td>-0.354524</td>\n",
       "      <td>0.230369</td>\n",
       "      <td>3.427140</td>\n",
       "      <td>-0.403580</td>\n",
       "      <td>...</td>\n",
       "      <td>3.499778</td>\n",
       "      <td>-0.441701</td>\n",
       "      <td>-0.533234</td>\n",
       "      <td>3.278971</td>\n",
       "      <td>-0.360298</td>\n",
       "      <td>-0.476572</td>\n",
       "      <td>3.268953</td>\n",
       "      <td>1</td>\n",
       "      <td>72057594037944340</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.357840</td>\n",
       "      <td>-0.420304</td>\n",
       "      <td>3.438846</td>\n",
       "      <td>-0.364956</td>\n",
       "      <td>-0.092426</td>\n",
       "      <td>3.442334</td>\n",
       "      <td>-0.354907</td>\n",
       "      <td>0.230391</td>\n",
       "      <td>3.427352</td>\n",
       "      <td>-0.405945</td>\n",
       "      <td>...</td>\n",
       "      <td>3.400878</td>\n",
       "      <td>-0.430001</td>\n",
       "      <td>-0.536492</td>\n",
       "      <td>3.278641</td>\n",
       "      <td>-0.358697</td>\n",
       "      <td>-0.471415</td>\n",
       "      <td>3.270685</td>\n",
       "      <td>1</td>\n",
       "      <td>72057594037944340</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.382997 -0.419442  3.449989 -0.366909 -0.092619  3.443680 -0.353380   \n",
       "1 -0.383146 -0.419292  3.450006 -0.367569 -0.092003  3.443895 -0.353885   \n",
       "2 -0.385776 -0.421191  3.449611 -0.369506 -0.092775  3.443796 -0.354571   \n",
       "3 -0.385807 -0.421205  3.449582 -0.369576 -0.092714  3.443878 -0.354524   \n",
       "4 -0.357840 -0.420304  3.438846 -0.364956 -0.092426  3.442334 -0.354907   \n",
       "\n",
       "          7         8         9    ...           68        69        70  \\\n",
       "0  0.229542  3.427116 -0.391862    ...     3.636719 -0.435790 -0.536338   \n",
       "1  0.230300  3.427162 -0.391820    ...     3.633053 -0.436031 -0.536649   \n",
       "2  0.230189  3.426965 -0.403822    ...     3.632370 -0.436489 -0.536484   \n",
       "3  0.230369  3.427140 -0.403580    ...     3.499778 -0.441701 -0.533234   \n",
       "4  0.230391  3.427352 -0.405945    ...     3.400878 -0.430001 -0.536492   \n",
       "\n",
       "         71        72        73        74  label                 id  video_id  \n",
       "0  3.280097 -0.364369 -0.491436  3.269750      1  72057594037944340         0  \n",
       "1  3.281972 -0.358806 -0.471054  3.269975      1  72057594037944340         0  \n",
       "2  3.286322 -0.358079 -0.470344  3.270202      1  72057594037944340         0  \n",
       "3  3.278971 -0.360298 -0.476572  3.268953      1  72057594037944340         0  \n",
       "4  3.278641 -0.358697 -0.471415  3.270685      1  72057594037944340         0  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading and prepping data\n",
    "#initially only one action\n",
    "dframe = pd.read_csv('./csv_data/action_1.csv')\n",
    "dframe2 = pd.read_csv('./csv_data/action_2.csv')\n",
    "dframe3 = pd.read_csv('./csv_data/action_3.csv')\n",
    "dframe4 = pd.read_csv('./csv_data/action_4.csv')\n",
    "dframe5 = pd.read_csv('./csv_data/action_5.csv')\n",
    "dframe6 = pd.read_csv('./csv_data/action_6.csv')\n",
    "dframe7 = pd.read_csv('./csv_data/action_7.csv')\n",
    "\n",
    "dframe8 = pd.read_csv('./csv_data/action_8.csv')\n",
    "dframe9 = pd.read_csv('./csv_data/action_9.csv')\n",
    "dframe10 = pd.read_csv('./csv_data/action_10.csv')\n",
    "dframe11 = pd.read_csv('./csv_data/action_11.csv')\n",
    "dframe12 = pd.read_csv('./csv_data/action_12.csv')\n",
    "dframe13 = pd.read_csv('./csv_data/action_13.csv')\n",
    "dframe14 = pd.read_csv('./csv_data/action_14.csv')\n",
    "\n",
    "dframe15 = pd.read_csv('./csv_data/action_15.csv')\n",
    "dframe16 = pd.read_csv('./csv_data/action_16.csv')\n",
    "dframe17 = pd.read_csv('./csv_data/action_17.csv')\n",
    "dframe18 = pd.read_csv('./csv_data/action_18.csv')\n",
    "dframe19 = pd.read_csv('./csv_data/action_19.csv')\n",
    "dframe20 = pd.read_csv('./csv_data/action_20.csv')\n",
    "dframe21 = pd.read_csv('./csv_data/action_21.csv')\n",
    "\n",
    "#to look at data\n",
    "dframe.iloc[0:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some utility functions to split the datasets and loading the datasets in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ (array([[ 0.       ,  0.       ,  0.       , ...,  0.0186279, -0.0719937,\n",
       "        -0.180239 ],\n",
       "       [ 0.       ,  0.       ,  0.       , ...,  0.0243399, -0.0517625,\n",
       "        -0.180031 ],\n",
       "       [ 0.       ,  0.       ,  0.       , ...,  0.0276977, -0.0491529,\n",
       "        -0.179409 ],\n",
       "       ..., \n",
       "       [ 0.       ,  0.       ,  0.       , ..., -0.0563203, -0.0113986,\n",
       "        -0.174284 ],\n",
       "       [ 0.       ,  0.       ,  0.       , ..., -0.0561737, -0.0162162,\n",
       "        -0.171437 ],\n",
       "       [ 0.       ,  0.       ,  0.       , ..., -0.0559275, -0.0062211,\n",
       "        -0.172233 ]]), 0),\n",
       "       (array([[ 0.        ,  0.        ,  0.        , ...,  0.01849598,\n",
       "         0.0721854 , -0.16189   ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.10443107,\n",
       "         0.05172237, -0.133567  ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.08676113,\n",
       "         0.05116256, -0.145192  ],\n",
       "       ..., \n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.10355284,\n",
       "         0.52594266, -0.431462  ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.09376174,\n",
       "         0.53507   , -0.434229  ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.08766792,\n",
       "         0.541823  , -0.422078  ]]), 0),\n",
       "       (array([[ 0.        ,  0.        ,  0.        , ...,  0.10299776,\n",
       "        -0.001346  , -0.226027  ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.10025404,\n",
       "        -0.0125163 , -0.230909  ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.09391637,\n",
       "        -0.0240066 , -0.245108  ],\n",
       "       ..., \n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.0862923 ,\n",
       "         0.0006496 , -0.251447  ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.09493048,\n",
       "        -0.0351646 , -0.236531  ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.11232334,\n",
       "        -0.0043682 , -0.221527  ]]), 0)], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making test and train split\n",
    "#the recentering has been done so that the pelvic joint is always at the origin\n",
    "#labels are to be zero indexed\n",
    "def train_test_split(dframe_list):\n",
    "    train_split = np.empty(0, dtype=object)\n",
    "    test_split = np.empty(0, dtype=object)\n",
    "    for dframe in dframe_list:\n",
    "        label = dframe.iloc[0,75]-1\n",
    "        num_samples = len(dframe.iloc[:,:])\n",
    "        video_ids = np.unique(dframe.iloc[:,-1].values)\n",
    "        train_video_ids = video_ids[:-35]\n",
    "        test_video_ids = video_ids[-35:]\n",
    "        train_split1 = np.empty(len(train_video_ids), dtype=object)\n",
    "        test_split1 = np.empty(len(test_video_ids), dtype=object)\n",
    "        for idx,i in enumerate(train_video_ids):\n",
    "            train_split1[idx] = dframe.loc[dframe['video_id'] == i].values[:,0:75]\n",
    "            for fidx, f in enumerate(train_split1[idx]):\n",
    "                f = np.reshape(f, (25,3))\n",
    "                f = f-f[0,:]\n",
    "                f = np.reshape(f, (1,75))\n",
    "                train_split1[idx][fidx] = f\n",
    "            train_split1[idx] = (train_split1[idx], label)\n",
    "\n",
    "        for idx,i in enumerate(test_video_ids):\n",
    "            test_split1[idx] = dframe.loc[dframe['video_id'] == i].values[:,0:75]\n",
    "            for fidx, f in enumerate(test_split1[idx]):\n",
    "                f = np.reshape(f, (25,3))\n",
    "                f = f-f[0,:]\n",
    "                f = np.reshape(f, (1,75))\n",
    "                test_split1[idx][fidx] = f\n",
    "            test_split1[idx] = (test_split1[idx], label)\n",
    "        train_split = np.concatenate((train_split, train_split1))\n",
    "        test_split = np.concatenate((test_split, test_split1))\n",
    "    return train_split, test_split\n",
    "\n",
    "train_split, test_split = train_test_split([dframe, dframe2, dframe3, dframe4, dframe5, dframe6, dframe7, dframe8, dframe9,\n",
    "                                           dframe10, dframe11, dframe12, dframe13, dframe14, dframe15, dframe16, dframe17,\n",
    "                                           dframe19, dframe20, dframe21])\n",
    "\n",
    "# #looking at split\n",
    "train_split[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.       ,  0.       ,  0.       , ...,  0.0531158,  0.0241104,\n",
       "         -0.408174 ],\n",
       "        [ 0.       ,  0.       ,  0.       , ...,  0.0704989, -0.0306856,\n",
       "         -0.356052 ],\n",
       "        [ 0.       ,  0.       ,  0.       , ...,  0.0713853, -0.0302602,\n",
       "         -0.355193 ],\n",
       "        ..., \n",
       "        [ 0.       ,  0.       ,  0.       , ..., -0.0484523,  0.0322823,\n",
       "         -0.457719 ],\n",
       "        [ 0.       ,  0.       ,  0.       , ..., -0.0546076,  0.0312212,\n",
       "         -0.447564 ],\n",
       "        [ 0.       ,  0.       ,  0.       , ..., -0.0565372,  0.0294197,\n",
       "         -0.431748 ]]), 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEQ_LEN = None\n",
    "def Data_gen( train_split, SEQ_LEN):\n",
    "    X = list(train_split)\n",
    "    while(True):\n",
    "        databatch = random.sample(X, 1)[0]\n",
    "        databatch, label = databatch[0], databatch[1]\n",
    "        if SEQ_LEN is not None:\n",
    "            if len(databatch) > SEQ_LEN:\n",
    "                databatch = databatch[0:SEQ_LEN]\n",
    "            elif len(databatch) < SEQ_LEN:\n",
    "                databatch = np.concatenate((databatch, np.zeros((SEQ_LEN - len(databatch), 75))))\n",
    "            else:\n",
    "                pass\n",
    "            yield databatch,label\n",
    "        else:\n",
    "            yield databatch,label\n",
    "ACTd = Data_gen(train_split, SEQ_LEN)\n",
    "#to look at batch created by Actd\n",
    "next(ACTd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.        ,  0.        ,  0.        , ..., -0.0767775 ,\n",
       "          0.20664589, -0.25646   ],\n",
       "        [ 0.        ,  0.        ,  0.        , ..., -0.0775596 ,\n",
       "          0.20458439, -0.256738  ],\n",
       "        [ 0.        ,  0.        ,  0.        , ..., -0.1224914 ,\n",
       "          0.23614434, -0.302416  ],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        , ..., -0.0581151 ,\n",
       "          0.6969325 , -0.243524  ],\n",
       "        [ 0.        ,  0.        ,  0.        , ..., -0.0198701 ,\n",
       "          0.5908162 , -0.171189  ],\n",
       "        [ 0.        ,  0.        ,  0.        , ..., -0.0330709 ,\n",
       "          0.5785297 , -0.147728  ]]), 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Val_data_gen(test_split):\n",
    "    X = list(test_split)\n",
    "    N = len(X)\n",
    "    ctr = 0\n",
    "    while True:\n",
    "        databatch, label = X[ctr]\n",
    "        ctr += 1\n",
    "        if ctr==N:\n",
    "            ctr=0\n",
    "        yield databatch, label\n",
    "ACTtest = Val_data_gen(test_split)\n",
    "next(ACTtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_val_accuracy(model):\n",
    "    N = len(list(test_split))\n",
    "    correct_count = 0\n",
    "    for i in range(N):\n",
    "        X,Y = next(ACTtest)\n",
    "        X_l = autograd.Variable(torch.from_numpy(X).float().cuda())\n",
    "        X_l = X_l.view(len(X), 1, -1)\n",
    "        y_hat, cord3, cord2_1, cord2_2, cord2_3 = model(X_l)\n",
    "        pred_label = y_hat.data.cpu().max(1)[1].numpy()[0]\n",
    "        if pred_label == Y:\n",
    "            correct_count += 1\n",
    "    return correct_count*100/N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Classifier model defination and intialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#action LSTM\n",
    "class LSTMClassifierX4(nn.Module):\n",
    "    def __init__(self, joints_dim, hidden_dim, label_size, batch_size, num_layers, kernel_size):\n",
    "        super(LSTMClassifierX4, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "        joints_dim2d = joints_dim - 25\n",
    "        \n",
    "        self.lstm3 = nn.LSTM(joints_dim, hidden_dim, num_layers=self.num_layers)\n",
    "        self.conv1_3 = nn.Conv1d(1, 1, kernel_size, stride=1, padding=1)\n",
    "        \n",
    "        self.lstm2_1 = nn.LSTM(joints_dim2d, hidden_dim, num_layers=self.num_layers)\n",
    "        self.conv1_2_1 = nn.Conv1d(1, 1, kernel_size, stride=1, padding=1)\n",
    "        self.lstm2_2 = nn.LSTM(joints_dim2d, hidden_dim, num_layers=self.num_layers)\n",
    "        self.conv1_2_2 = nn.Conv1d(1, 1, kernel_size, stride=1, padding=1)\n",
    "        self.lstm2_3 = nn.LSTM(joints_dim2d, hidden_dim, num_layers=self.num_layers)\n",
    "        self.conv1_2_3 = nn.Conv1d(1, 1, kernel_size, stride=1, padding=1)\n",
    "        \n",
    "        self.dense3 = nn.Linear(hidden_dim, joints_dim)\n",
    "        self.dense2_1 = nn.Linear(hidden_dim, joints_dim2d)\n",
    "        self.dense2_2 = nn.Linear(hidden_dim, joints_dim2d)\n",
    "        self.dense2_3 = nn.Linear(hidden_dim, joints_dim2d)\n",
    "        \n",
    "        self.hidden3 = self.init_hidden3()\n",
    "        self.hidden2_1 = self.init_hidden2_1()\n",
    "        self.hidden2_2 = self.init_hidden2_2()\n",
    "        self.hidden2_3 = self.init_hidden2_3()\n",
    "        \n",
    "        self.hidden2label = nn.Linear(hidden_dim, label_size)\n",
    "    \n",
    "    def init_hidden3(self):\n",
    "        # the first is the hidden h\n",
    "        # the second is the cell  c\n",
    "        return (autograd.Variable(torch.zeros(self.num_layers, self.batch_size, self.hidden_dim).cuda()),\n",
    "                autograd.Variable(torch.zeros(self.num_layers, self.batch_size, self.hidden_dim).cuda()))\n",
    "    def init_hidden2_1(self):\n",
    "        # the first is the hidden h\n",
    "        # the second is the cell  c\n",
    "        return (autograd.Variable(torch.zeros(self.num_layers, self.batch_size, self.hidden_dim).cuda()),\n",
    "                autograd.Variable(torch.zeros(self.num_layers, self.batch_size, self.hidden_dim).cuda()))\n",
    "    def init_hidden2_2(self):\n",
    "        # the first is the hidden h\n",
    "        # the second is the cell  c\n",
    "        return (autograd.Variable(torch.zeros(self.num_layers, self.batch_size, self.hidden_dim).cuda()),\n",
    "                autograd.Variable(torch.zeros(self.num_layers, self.batch_size, self.hidden_dim).cuda()))\n",
    "    def init_hidden2_3(self):\n",
    "        # the first is the hidden h\n",
    "        # the second is the cell  c\n",
    "        return (autograd.Variable(torch.zeros(self.num_layers, self.batch_size, self.hidden_dim).cuda()),\n",
    "                autograd.Variable(torch.zeros(self.num_layers, self.batch_size, self.hidden_dim).cuda()))\n",
    "    \n",
    "    \n",
    "    def forward(self, joints3d_vec):\n",
    "        x3 = joints3d_vec\n",
    "        x3_d = joints3d_vec.data.cpu().numpy()\n",
    "        x2_d = np.reshape(x3_d, (-1,25,3))\n",
    "#         print(x2_d)\n",
    "        x2_1_d = np.reshape(x2_d[:,:,1:3], (-1,1,50))\n",
    "        x2_2_d = np.reshape(x2_d[:,:,0:2], (-1,1,50))\n",
    "        x2_3_d = np.reshape(x2_d[:,:,[0,2]], (-1,1,50))\n",
    "#         print(x2_3_d)\n",
    "        x2_1 = autograd.Variable(torch.from_numpy(x2_1_d).cuda())\n",
    "        x2_2 = autograd.Variable(torch.from_numpy(x2_2_d).cuda())\n",
    "        x2_3 = autograd.Variable(torch.from_numpy(x2_3_d).cuda())\n",
    "\n",
    "        lstm_out3, self.hidden3 = self.lstm3(x3, self.hidden3)\n",
    "        lstm_out2_1, self.hidden2_1 = self.lstm2_1(x2_1, self.hidden2_1)\n",
    "        lstm_out2_2, self.hidden2_2 = self.lstm2_2(x2_2, self.hidden2_2)\n",
    "        lstm_out2_3, self.hidden2_3 = self.lstm2_3(x2_3, self.hidden2_3)\n",
    "\n",
    "        t3 = lstm_out3[-1].view(self.batch_size,1,-1)\n",
    "        t2_1 = lstm_out2_1[-1].view(self.batch_size,1,-1)\n",
    "        t2_2 = lstm_out2_2[-1].view(self.batch_size,1,-1)\n",
    "        t2_3 = lstm_out2_3[-1].view(self.batch_size,1,-1)\n",
    "\n",
    "        y3 = self.conv1_3(t3)\n",
    "        y2_1 = self.conv1_2_1(t2_1)\n",
    "        y2_2 = self.conv1_2_2(t2_2)\n",
    "        y2_3 = self.conv1_2_3(t2_3)\n",
    "        \n",
    "        yf = y3+y2_1+y2_2+y2_3    \n",
    "        yf = yf.view(-1, self.hidden_dim)\n",
    "        y  = self.hidden2label(yf)\n",
    "        \n",
    "        ## for outputs of other timesteps\n",
    "        t_prime3 = lstm_out3[:-1]\n",
    "        t_prime2_1 = lstm_out2_1[:-1]\n",
    "        t_prime2_2 = lstm_out2_2[:-1]\n",
    "        t_prime2_3 = lstm_out2_3[:-1]\n",
    "        \n",
    "        y3_others = autograd.Variable(torch.zeros((t_prime3.size()[0], t_prime3.size()[1], 75)).cuda())\n",
    "        y2_1_others = autograd.Variable(torch.zeros((t_prime2_1.size()[0], t_prime2_1.size()[1], 50)).cuda())\n",
    "        y2_2_others = autograd.Variable(torch.zeros((t_prime2_2.size()[0], t_prime2_2.size()[1], 50)).cuda())\n",
    "        y2_3_others = autograd.Variable(torch.zeros((t_prime2_3.size()[0], t_prime2_3.size()[1], 50)).cuda())\n",
    "        \n",
    "        for idx,tp in enumerate(t_prime3):\n",
    "            y3_others[idx, :, :] = self.dense3(tp)\n",
    "        for idx,tp in enumerate(t_prime2_1):\n",
    "            y2_1_others[idx, :, :] = self.dense2_1(tp)\n",
    "        for idx,tp in enumerate(t_prime2_2):\n",
    "            y2_2_others[idx, :, :] = self.dense2_2(tp)\n",
    "        for idx,tp in enumerate(t_prime3):\n",
    "            y2_3_others[idx, :, :] = self.dense2_3(tp)\n",
    "        log_probs = F.log_softmax(y, dim=1)\n",
    "        return log_probs, y3_others, y2_1_others, y2_2_others, y2_3_others #others as in the output from the cells behind the last cell\n",
    "#instanstiating a model\n",
    "model0 = LSTMClassifierX4(75, 512, 21, 1, 2, 3)\n",
    "#to do stuff in CUDA\n",
    "model0 = model0.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-221aa101254a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_val_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-12e0ed10d27b>\u001b[0m in \u001b[0;36mevaluate_val_accuracy\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mX_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mX_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcord3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcord2_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcord2_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcord2_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mpred_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpred_label\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DeepCV3.5/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-0a4da21bff80>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, joints3d_vec)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mt_prime2_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_out2_3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0my3_others\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_prime3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_prime3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0my2_1_others\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_prime2_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_prime2_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0my2_2_others\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_prime2_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_prime2_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DeepCV3.5/lib/python3.5/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36m_cuda\u001b[0;34m(self, device, async)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mnew_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evaluate_val_accuracy(model0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training function\n",
    "def train(model, num_epoch, num_iter, rec_interval, disp_interval):\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 8e-6)\n",
    "    loss_values = []\n",
    "    avg_loss_values = []\n",
    "    rec_step = 0\n",
    "    print('Starting the training ...')\n",
    "    torch.cuda.synchronize()\n",
    "    for eph in range(num_epoch):\n",
    "        print('epoch {} starting ...'.format(eph))\n",
    "        avg_loss = 0\n",
    "        n_samples = 0\n",
    "        torch.cuda.synchronize()\n",
    "        for i in range(num_iter):\n",
    "            model.hidden3 = (model.hidden3[0].detach(), model.hidden3[1].detach())\n",
    "            model.hidden2_1 = (model.hidden2_1[0].detach(), model.hidden2_1[1].detach())\n",
    "            model.hidden2_2 = (model.hidden2_2[0].detach(), model.hidden2_2[1].detach())\n",
    "            model.hidden2_3 = (model.hidden2_3[0].detach(), model.hidden2_3[1].detach())\n",
    "            model.zero_grad()\n",
    "            X,Y = next(ACTd)\n",
    "            n_samples += len(X)\n",
    "            X = autograd.Variable(torch.from_numpy(X).float().cuda())\n",
    "            X = X.view(len(X), 1, -1)\n",
    "            Y = autograd.Variable(torch.LongTensor(np.array([Y])).cuda())\n",
    "            \n",
    "            X2 = X.view(-1, 25, 3)\n",
    "            X2_1 = X2[:,:,1:3].contiguous().view(-1, 1, 50)\n",
    "            X2_2 = X2[:,:,0:2].contiguous().view(-1, 1, 50)\n",
    "            X2_3 = X2[:,:,[0,2]].contiguous().view(-1, 1, 50)\n",
    "            \n",
    "            y_hat, cord3, cord2_1, cord2_2, cord2_3 = model(X)\n",
    "            \n",
    "            loss_classification = F.cross_entropy(y_hat, Y)\n",
    "            loss_regr3d = F.mse_loss(cord3, X)\n",
    "            loss_regr2d_1 = F.mse_loss(cord2_1, X2_1)\n",
    "            loss_regr2d_2 = F.mse_loss(cord2_2, X2_2)\n",
    "            loss_regr2d_3 = F.mse_loss(cord2_3, X2_3)\n",
    "            \n",
    "            loss = loss_classification + loss_regr3d + loss_regr2d_1 + loss_regr2d_2 + loss_regr2d_3\n",
    "            avg_loss += loss.data[0]\n",
    "            \n",
    "            if i % disp_interval == 0:\n",
    "                print('epoch: %d iterations: %d loss :%g' % (eph, i, loss.data[0]))\n",
    "            if rec_step%rec_interval==0:\n",
    "                loss_values.append(loss.data[0])\n",
    "            \n",
    "            loss.backward()     \n",
    "            optimizer.step()\n",
    "            rec_step += 1\n",
    "            \n",
    "        avg_loss /= n_samples\n",
    "        avg_loss_values.append(avg_loss)\n",
    "        #evaluating model accuracy\n",
    "        acc = evaluate_accuracy(model, ACTtest)\n",
    "        print('epoch: {} <====train track===> avg_loss: {}, accuracy: {}% \\n'.format(eph, avg_loss, acc))\n",
    "    return loss_values, avg_loss_values\n",
    "\n",
    "\n",
    "loss_vals, avg_loss_vals = train(model0, 100, 1000, 2, 100)\n",
    "plt.figure()\n",
    "plt.plot(loss_vals)\n",
    "plt.figure()\n",
    "plt.plot(avg_loss_vals)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('avg loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## observations\n",
    "* better to use the log_softmax instead of softmax\n",
    "* decrease lr succicesively to get better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training function\n",
    "def train(model, num_epoch, num_iter, rec_interval, disp_interval):\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 8e-6)\n",
    "    loss_values = []\n",
    "    avg_loss_values = []\n",
    "    rec_step = 0\n",
    "    print('Starting the training ...')\n",
    "    torch.cuda.synchronize()\n",
    "    for eph in range(num_epoch):\n",
    "        print('epoch {} starting ...'.format(eph))\n",
    "        avg_loss = 0\n",
    "        n_samples = 0\n",
    "        torch.cuda.synchronize()\n",
    "        for i in range(num_iter):\n",
    "            model.hidden3 = (model.hidden3[0].detach(), model.hidden3[1].detach())\n",
    "            model.hidden2_1 = (model.hidden2_1[0].detach(), model.hidden2_1[1].detach())\n",
    "            model.hidden2_2 = (model.hidden2_2[0].detach(), model.hidden2_2[1].detach())\n",
    "            model.hidden2_3 = (model.hidden2_3[0].detach(), model.hidden2_3[1].detach())\n",
    "            model.zero_grad()\n",
    "            X,Y = next(ACTd)\n",
    "            n_samples += len(X)\n",
    "            X = autograd.Variable(torch.from_numpy(X).float().cuda())\n",
    "            X = X.view(len(X), 1, -1)\n",
    "            Y = autograd.Variable(torch.LongTensor(np.array([Y])).cuda())\n",
    "            \n",
    "            X2 = X.view(-1, 25, 3)\n",
    "            X2_1 = X2[:,:,1:3].contiguous().view(-1, 1, 50)\n",
    "            X2_2 = X2[:,:,0:2].contiguous().view(-1, 1, 50)\n",
    "            X2_3 = X2[:,:,[0,2]].contiguous().view(-1, 1, 50)\n",
    "            \n",
    "            y_hat, cord3, cord2_1, cord2_2, cord2_3 = model(X)\n",
    "#             print('cord3 : {}'.format(cord3.size()))\n",
    "#             print('X : {}'.format(X.size()))\n",
    "#             print('cord3 : {}'.format(cord3.size()))\n",
    "            \n",
    "            loss_classification = F.cross_entropy(y_hat, Y)\n",
    "            loss_regr3d = F.mse_loss(cord3, X)\n",
    "#             print('loss_regr3d : {}'.format(loss_regr3d))\n",
    "            \n",
    "            loss_regr2d_1 = F.mse_loss(cord2_1, X2_1)\n",
    "            loss_regr2d_2 = F.mse_loss(cord2_2, X2_2)\n",
    "            loss_regr2d_3 = F.mse_loss(cord2_3, X2_3)\n",
    "            \n",
    "            loss = loss_classification + loss_regr3d + loss_regr2d_1 + loss_regr2d_2 + loss_regr2d_3\n",
    "#             print(loss)\n",
    "            avg_loss += loss.data[0]\n",
    "            \n",
    "            if i % disp_interval == 0:\n",
    "                print('epoch: %d iterations: %d loss :%g' % (eph, i, loss.data[0]))\n",
    "            if rec_step%rec_interval==0:\n",
    "                loss_values.append(loss.data[0])\n",
    "            \n",
    "            loss.backward()     \n",
    "            optimizer.step()\n",
    "            rec_step += 1\n",
    "            \n",
    "        avg_loss /= n_samples\n",
    "        avg_loss_values.append(avg_loss)\n",
    "        #evaluating model accuracy\n",
    "        acc = evaluate_accuracy(model, ACTtest)\n",
    "        print('epoch: {} <====train track===> avg_loss: {}, accuracy: {}% \\n'.format(eph, avg_loss, acc))\n",
    "    return loss_values, avg_loss_values\n",
    "\n",
    "\n",
    "loss_vals, avg_loss_vals = train(model0, 100, 1000, 2, 100)\n",
    "plt.figure()\n",
    "plt.plot(loss_vals)\n",
    "plt.figure()\n",
    "plt.plot(avg_loss_vals)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('avg loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = autograd.Variable(torch.rand(3,5).cuda())\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model\n",
    "def save_model(model_name, path, model):\n",
    "    p = path+'/'+model_name\n",
    "    print('saving at {}'.format(p))\n",
    "    torch.save(model.state_dict(), p)\n",
    "    print('saved at {}'.format(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model('LSTMClassifierX1_c7.pth', './checkpoints', model0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtest = LSTMClassifier(75, 512, 7, 1, 2, 3).cuda()\n",
    "mtest.load_state_dict(torch.load('./checkpoints/LSTMClassifierX1_c7.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtest.lstm.weight_ih_l0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
